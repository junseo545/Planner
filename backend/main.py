# ========================================
# ì—¬í–‰ í”Œë˜ë„ˆ AI ë°±ì—”ë“œ ì„œë²„
# ========================================
# ì´ íŒŒì¼ì€ ì—¬í–‰ ê³„íšì„ AIë¡œ ìƒì„±í•˜ê³  í˜¸í…” ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì›¹ ì„œë²„ì…ë‹ˆë‹¤.
# FastAPI í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.

# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤ (import)
from fastapi import FastAPI, HTTPException  # FastAPI: ì›¹ ì„œë²„ í”„ë ˆì„ì›Œí¬, HTTPException: ì—ëŸ¬ ì²˜ë¦¬ìš©
from fastapi.middleware.cors import CORSMiddleware  # CORS: ì›¹ ë¸Œë¼ìš°ì €ì˜ ë³´ì•ˆ ì •ì±… ê´€ë ¨
from fastapi.responses import StreamingResponse  # SSEë¥¼ ìœ„í•œ StreamingResponse
from pydantic import BaseModel  # ë°ì´í„° ê²€ì¦ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from typing import List, Optional  # íƒ€ì… íŒíŠ¸ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import openai  # OpenAI API ì‚¬ìš©ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os  # ìš´ì˜ì²´ì œ ê´€ë ¨ ê¸°ëŠ¥ (í™˜ê²½ë³€ìˆ˜ ë“±)
from dotenv import load_dotenv  # .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ë¥¼ ë¡œë“œí•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
import json  # JSON ë°ì´í„° ì²˜ë¦¬ìš©
import logging  # ë¡œê·¸ ê¸°ë¡ìš©
from datetime import datetime, timedelta  # ë‚ ì§œì™€ ì‹œê°„ ì²˜ë¦¬ìš©
import urllib.parse  # URL ì¸ì½”ë”©ìš©
import requests  # HTTP ìš”ì²­ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import re  # ì •ê·œí‘œí˜„ì‹ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import asyncio  # ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from kakao_location_validator import KakaoLocationValidator, PlaceValidationResult
from kakao_geocoding import KakaoGeocodingService
from kakao_place_service import KakaoPlaceService

load_dotenv()

# ì¹´ì¹´ì˜¤ API ì¸ì¦
KAKAO_API_KEY = os.getenv("KAKAO_API_KEY")

# ========================================
# ì¹´ì¹´ì˜¤ ë¡œì»¬ API ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
# ========================================
class KakaoLocalService:
    """ì¹´ì¹´ì˜¤ ë¡œì»¬ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¥ì†Œ ê²€ìƒ‰ ë° ê²€ì¦ì„ ìˆ˜í–‰í•˜ëŠ” ì„œë¹„ìŠ¤"""
    
    def __init__(self, api_key: str = None):
        self.api_key = api_key or kakao_api_key
        self.base_url = "https://dapi.kakao.com/v2/local/search/keyword.json"
        
    def search_place(self, query: str, region: str = None) -> dict:
        """
        ì¹´ì¹´ì˜¤ ë¡œì»¬ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¥ì†Œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            query: ê²€ìƒ‰í•  ì¥ì†Œëª…
            region: ì§€ì—­ í•„í„° (ì„ íƒì‚¬í•­)
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (ì¥ì†Œ ì •ë³´ í¬í•¨)
        """
        if not self.api_key:
            logger.warning("ì¹´ì¹´ì˜¤ API í‚¤ê°€ ì—†ì–´ ì¥ì†Œ ê²€ìƒ‰ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return None
            
        headers = {
            "Authorization": f"KakaoAK {self.api_key}"
        }
        
        params = {
            "query": query,
            "size": 5  # ìµœëŒ€ 5ê°œ ê²°ê³¼ë§Œ ê°€ì ¸ì˜¤ê¸°
        }
        
        # ì§€ì—­ì´ ì§€ì •ëœ ê²½ìš° ê²€ìƒ‰ì–´ì— í¬í•¨
        if region:
            params["query"] = f"{region} {query}"
            
        try:
            response = requests.get(self.base_url, headers=headers, params=params)
            response.raise_for_status()
            
            data = response.json()
            documents = data.get('documents', [])
            
            if documents:
                # ì²« ë²ˆì§¸ ê²°ê³¼ ë°˜í™˜ (ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼)
                place = documents[0]
                return {
                    'found': True,
                    'name': place.get('place_name', ''),
                    'address': place.get('address_name', ''),
                    'road_address': place.get('road_address_name', ''),
                    'category': place.get('category_name', ''),
                    'phone': place.get('phone', ''),
                    'x': place.get('x', ''),  # ê²½ë„
                    'y': place.get('y', ''),  # ìœ„ë„
                    'url': place.get('place_url', '')
                }
            else:
                logger.warning(f"ì¹´ì¹´ì˜¤ APIì—ì„œ '{query}' ì¥ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return {'found': False, 'query': query}
                
        except requests.exceptions.RequestException as e:
            logger.error(f"ì¹´ì¹´ì˜¤ API ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
            return {'found': False, 'error': str(e), 'query': query}
            
    def _clean_place_name(self, place_name: str) -> str:
        """ì¥ì†Œëª…ì—ì„œ ë¶ˆí•„ìš”í•œ ë‹¨ì–´ë“¤ì„ ì œê±°í•©ë‹ˆë‹¤."""
        # ë¶ˆí•„ìš”í•œ ë‹¨ì–´ë“¤ ì œê±°
        remove_words = [
            'ë°©ë¬¸', 'ê´€ëŒ', 'íˆ¬ì–´', 'ì²´í—˜', 'êµ¬ê²½', 'ì‚°ì±…', 'ë‘˜ëŸ¬ë³´ê¸°', 'íƒë°©', 'ê²¬í•™',
            'ê°€ê¸°', 'ë³´ê¸°', 'í•˜ê¸°', 'ì¦ê¸°ê¸°', 'ê±·ê¸°', 'ì˜¤ë¥´ê¸°', 'ë‚´ë ¤ê°€ê¸°', 'ì˜¬ë¼ê°€ê¸°',
            'ì—ì„œ', 'ê¹Œì§€', 'ìœ¼ë¡œ', 'ë¥¼', 'ì„', 'ì˜', 'ì—', 'ì™€', 'ê³¼', 'ë„', 'ë§Œ',
            'ì ì‹¬', 'ì €ë…', 'ì•„ì¹¨', 'ì‹ì‚¬', 'ë¨¹ê¸°', 'ë§›ë³´ê¸°', 'ì‹œì‹',
            'íœ´ì‹', 'ì‰¬ê¸°', 'ì ì‹œ', 'ì ê¹', 'êµ¬ì…', 'ì‡¼í•‘', 'êµ¬ë§¤'
        ]
        
        cleaned = place_name
        for word in remove_words:
            cleaned = cleaned.replace(word, '').strip()
        
        return cleaned if cleaned else place_name

    def _is_relevant_result(self, search_keyword: str, search_result: dict, original_title: str) -> bool:
        """ê²€ìƒ‰ ê²°ê³¼ê°€ ì›ë³¸ í‚¤ì›Œë“œì™€ ê´€ë ¨ì„±ì´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        result_name = search_result.get('name', '').lower()
        result_category = search_result.get('category', '').lower()
        
        # ì›ë³¸ ì œëª©ê³¼ ê²€ìƒ‰ í‚¤ì›Œë“œì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        original_keywords = self._extract_core_keywords(original_title.lower())
        search_keywords = self._extract_core_keywords(search_keyword.lower())
        
        # í•µì‹¬ í‚¤ì›Œë“œê°€ ê²€ìƒ‰ ê²°ê³¼ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        for keyword in original_keywords + search_keywords:
            if len(keyword) > 2 and keyword in result_name:
                return True
        
        # ë¶€ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ í•„í„°ë§ (ìš”ì–‘, ë³‘ì›, ì˜ë£Œ ë“±)
        inappropriate_categories = [
            'ìš”ì–‘', 'ë³‘ì›', 'ì˜ë£Œ', 'í´ë¦¬ë‹‰', 'í•œì˜ì›', 'ì¹˜ê³¼', 'ì•½êµ­',
            'ë¶€ë™ì‚°', 'í•™ì›', 'í•™êµ', 'ì‚¬ë¬´ì‹¤', 'íšŒì‚¬'
        ]
        
        for inappropriate in inappropriate_categories:
            if inappropriate in result_name or inappropriate in result_category:
                logger.warning(f"ë¶€ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ ê°ì§€: {result_name} ({result_category})")
                return False
        
        return True
    
    def _extract_core_keywords(self, text: str) -> list:
        """í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        import re
        
        # í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ ì œê±°
        cleaned = re.sub(r'[^\w\s]', ' ', text)
        words = cleaned.split()
        
        # ì˜ë¯¸ìˆëŠ” í‚¤ì›Œë“œë§Œ ì¶”ì¶œ (2ê¸€ì ì´ìƒ)
        core_keywords = []
        for word in words:
            if len(word) >= 2:
                core_keywords.append(word)
        
        return core_keywords

    def _extract_specific_place_names(self, title: str) -> list:
        """ì œëª©ì—ì„œ êµ¬ì²´ì ì¸ ì¥ì†Œëª…ì„ ìš°ì„ ì ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        import re
        
        candidates = []
        
        # 1. ë³µí•© ì¥ì†Œëª… íŒ¨í„´ (ì˜ˆ: "ê²½ì£¼ ì–‘ë™ë§ˆì„", "ë¶€ì‚° í•´ìš´ëŒ€ í•´ìˆ˜ìš•ì¥")
        # ì§€ì—­ëª… + êµ¬ì²´ì  ì¥ì†Œëª… íŒ¨í„´
        region_place_patterns = [
            r'(\w+)\s+(\w+ë§ˆì„)',      # ê²½ì£¼ ì–‘ë™ë§ˆì„
            r'(\w+)\s+(\w+\s*í•´ìˆ˜ìš•ì¥)', # ë¶€ì‚° í•´ìš´ëŒ€ í•´ìˆ˜ìš•ì¥
            r'(\w+)\s+(\w+\s*ìœ ì ì§€)',   # ê²½ì£¼ ì›”ì„± ìœ ì ì§€
            r'(\w+)\s+(\w+\s*ë°•ë¬¼ê´€)',   # ê²½ì£¼ êµ­ë¦½ë°•ë¬¼ê´€
            r'(\w+)\s+(\w+\s*ê³µì›)',     # ë¶€ì‚° ìš©ë‘ì‚° ê³µì›
            r'(\w+)\s+(\w+\s*ì‚¬ì°°)',     # ê²½ì£¼ ë¶ˆêµ­ì‚¬
            r'(\w+)\s+(\w+\s*ê¶)',       # ê²½ì£¼ ë™ê¶
            r'(\w+)\s+(\w+\s*ì„±)',       # ê²½ì£¼ ì›”ì„±
            r'(\w+)\s+(\w+\s*í„°)',       # ê²½ì£¼ ì²¨ì„±ëŒ€í„°
            r'(\w+)\s+(\w+\s*ë‹¤ë¦¬)',     # ë¶€ì‚° ê´‘ì•ˆëŒ€êµ
            r'(\w+)\s+(\w+\s*ì‹œì¥)',     # ë¶€ì‚° ìê°ˆì¹˜ì‹œì¥
        ]
        
        for pattern in region_place_patterns:
            matches = re.findall(pattern, title)
            for match in matches:
                if len(match) == 2:
                    region, place = match
                    # ì „ì²´ ì¥ì†Œëª…ì„ ìš°ì„ ìˆœìœ„ë¡œ
                    full_place = f"{region} {place}".strip()
                    candidates.append(full_place)
                    # êµ¬ì²´ì ì¸ ì¥ì†Œëª…ë§Œë„ ì¶”ê°€ (2ìˆœìœ„)
                    if place.strip() not in candidates:
                        candidates.append(place.strip())
        
        # 2. ë‹¨ë… êµ¬ì²´ì  ì¥ì†Œëª… íŒ¨í„´
        specific_patterns = [
            r'(\w+ë§ˆì„)',      # ì–‘ë™ë§ˆì„, í•˜íšŒë§ˆì„
            r'(\w+\s*í•´ìˆ˜ìš•ì¥)', # í•´ìš´ëŒ€í•´ìˆ˜ìš•ì¥, ê´‘ì•ˆë¦¬ í•´ìˆ˜ìš•ì¥
            r'(\w+\s*í•´ë³€)',     # ì •ë™ì§„ í•´ë³€, ê²½í¬ í•´ë³€
            r'(\w+\s*ìœ ì ì§€)',   # ì›”ì„± ìœ ì ì§€, ëŒ€ë¦‰ì› ìœ ì ì§€
            r'(\w+\s*ë°•ë¬¼ê´€)',   # êµ­ë¦½ê²½ì£¼ë°•ë¬¼ê´€, ë¶€ì‚°ì‹œë¦½ë°•ë¬¼ê´€
            r'(\w+\s*ë¯¸ìˆ ê´€)',   # ë¶€ì‚°ì‹œë¦½ë¯¸ìˆ ê´€
            r'(\w+\s*ê³µì›)',     # ìš©ë‘ì‚°ê³µì›, í•´ìš´ëŒ€ê³µì›
            r'(\w+ì‚¬)',         # ë¶ˆêµ­ì‚¬, ì„êµ´ì•”
            r'(\w+ê¶)',         # ë™ê¶, ì›”ê¶
            r'(\w+ì„±)',         # ì›”ì„±, ë™ì„±
            r'(\w+ëŒ€)',         # ì²¨ì„±ëŒ€, ì„ë¹™ê³ 
            r'(\w+\s*ë‹¤ë¦¬)',     # ê´‘ì•ˆëŒ€êµ, ë¶€ì‚°ëŒ€êµ
            r'(\w+\s*ì‹œì¥)',     # ìê°ˆì¹˜ì‹œì¥, êµ­ì œì‹œì¥
            r'(\w+\s*íƒ€ì›Œ)',     # ë¶€ì‚°íƒ€ì›Œ, ë¡¯ë°íƒ€ì›Œ
            r'(\w+\s*ì„¼í„°)',     # ë²¡ìŠ¤ì½”, ë¬¸í™”ì„¼í„°
            r'(\w+\s*ì—­)',       # ì •ë™ì§„ì—­, ê°•ë¦‰ì—­
        ]
        
        for pattern in specific_patterns:
            matches = re.findall(pattern, title)
            for match in matches:
                if isinstance(match, str) and len(match.strip()) > 1:
                    # ë¶€ì ì ˆí•œ ë‹¨ì–´ í•„í„°ë§
                    if self._is_real_place_name(match.strip()) and match.strip() not in candidates:
                        candidates.append(match.strip())
        
        return candidates

    def _extract_place_name_from_title(self, title: str) -> list:
        """ì œëª©ì—ì„œ ì‹¤ì œ ì¥ì†Œëª…ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        import re
        
        # ì¥ì†Œëª… í›„ë³´ë“¤
        candidates = []
        
        # 1. êµ¬ì²´ì ì¸ ì¥ì†Œëª… íŒ¨í„´ ìš°ì„  ì¶”ì¶œ (ê°€ì¥ ì¤‘ìš”!)
        specific_place_candidates = self._extract_specific_place_names(title)
        candidates.extend(specific_place_candidates)
        
        # 2. ì •ì œëœ ì œëª© (ë¶ˆí•„ìš”í•œ ë‹¨ì–´ ì œê±°)
        cleaned_title = self._clean_place_name(title)
        if cleaned_title and cleaned_title != title and len(cleaned_title.strip()) > 1:
            # ì´ë¯¸ êµ¬ì²´ì ì¸ ì¥ì†Œëª…ì´ ìˆìœ¼ë©´ ì¤‘ë³µ ë°©ì§€
            if cleaned_title.strip() not in candidates:
                candidates.append(cleaned_title.strip())
        
        # 3. ê´„í˜¸ ì•ˆ ë‚´ìš© ì œê±°
        no_brackets = re.sub(r'\([^)]*\)', '', title).strip()
        if no_brackets and no_brackets != title and len(no_brackets.strip()) > 1:
            # ë¶ˆí•„ìš”í•œ ë‹¨ì–´ë„ í•¨ê»˜ ì œê±°
            no_brackets_cleaned = self._clean_place_name(no_brackets)
            if no_brackets_cleaned and no_brackets_cleaned not in candidates:
                candidates.append(no_brackets_cleaned)
        
        # 4. ë§ˆì§€ë§‰ ë‹¨ì–´ ì œê±° (ë³´í†µ ë™ì‘ ë‹¨ì–´)
        words = title.split()
        if len(words) > 1:
            without_last = ' '.join(words[:-1]).strip()
            if len(without_last) > 1 and without_last not in candidates:
                candidates.append(without_last)
        
        # 5. ì²« ë²ˆì§¸ ë‹¨ì–´ë§Œ (ì§€ì—­ëª…, ìµœí›„ ìˆ˜ë‹¨)
        first_word = title.split()[0] if title.split() else ""
        if first_word and len(first_word) > 1 and first_word not in candidates:
            candidates.append(first_word)
        
        # ì¤‘ë³µ ì œê±° ë° ë¹ˆ ë¬¸ìì—´ ì œê±°
        unique_candidates = []
        for candidate in candidates:
            candidate = candidate.strip()
            if candidate and candidate not in unique_candidates and len(candidate) > 1:
                unique_candidates.append(candidate)
        
        return unique_candidates

    def _is_detailed_address(self, text: str) -> bool:
        """í…ìŠ¤íŠ¸ê°€ ìƒì„¸ ì£¼ì†Œì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        import re
        
        # ìƒì„¸ ì£¼ì†Œ íŒ¨í„´ (ì‹œ/êµ°/êµ¬/ë™/ë¦¬/ë©´ ë“±ì´ í¬í•¨ëœ ê²½ìš°)
        address_patterns = [
            r'\w+ì‹œ\s+\w+êµ¬',      # ì„œìš¸ì‹œ ê°•ë‚¨êµ¬
            r'\w+ì‹œ\s+\w+êµ°',      # ê²½ê¸°ë„ í‰íƒì‹œ
            r'\w+ë„\s+\w+ì‹œ',      # ê²½ê¸°ë„ ìˆ˜ì›ì‹œ
            r'\w+ì‹œ\s+\w+ë©´',      # ê°•ë¦‰ì‹œ ê°•ë™ë©´
            r'\w+êµ¬\s+\w+ë™',      # ê°•ë‚¨êµ¬ ì—­ì‚¼ë™
            r'\w+ë™\s+\w+ë¦¬',      # ê°•ë™ë©´ ì •ë™ì§„ë¦¬
            r'\w+ë©´\s+\w+ë¦¬',      # ê°•ë™ë©´ ì •ë™ì§„ë¦¬
            r'\d+ë²ˆì§€',            # 123ë²ˆì§€
            r'\d+-\d+',            # 123-45
        ]
        
        for pattern in address_patterns:
            if re.search(pattern, text):
                return True
                
        # ì£¼ì†Œ í‚¤ì›Œë“œê°€ ë§ì´ í¬í•¨ëœ ê²½ìš°
        address_keywords = ['ì‹œ', 'êµ°', 'êµ¬', 'ë™', 'ë¦¬', 'ë©´', 'ë²ˆì§€', 'ë¡œ', 'ê¸¸']
        keyword_count = sum(1 for keyword in address_keywords if keyword in text)
        
        # 3ê°œ ì´ìƒì˜ ì£¼ì†Œ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ìƒì„¸ ì£¼ì†Œë¡œ íŒë‹¨
        return keyword_count >= 3

    def _is_real_place_name(self, text: str) -> bool:
        """í…ìŠ¤íŠ¸ê°€ ì‹¤ì œ ì¥ì†Œëª…ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        import re
        
        # ëª…í™•í•œ ì¥ì†Œëª… íŒ¨í„´ë“¤
        place_patterns = [
            r'\w+ì„±$',          # ë™ë˜ìì„±, ê²½ë³µê¶ì„±
            r'\w+ê¶$',          # ê²½ë³µê¶, ì°½ë•ê¶
            r'\w+ì‚¬$',          # ë¶ˆêµ­ì‚¬, í•´ì¸ì‚¬
            r'\w+ì•”$',          # ì„êµ´ì•”, ë³´ë¬¸ì•”
            r'\w+ëŒ€$',          # ì²¨ì„±ëŒ€, ì„ë¹™ê³ 
            r'\w+ê´€$',          # ë°•ë¬¼ê´€, ë¯¸ìˆ ê´€
            r'\w+ì›$',          # ê³µì›, ë™ë¬¼ì›
            r'\w+ì¥$',          # ì‹œì¥, ê´‘ì¥
            r'\w+êµ$',          # ë‹¤ë¦¬ (ê´‘ì•ˆëŒ€êµ)
            r'\w+íƒ‘$',          # íƒ‘, íƒ€ì›Œ
            r'\w+ë§ˆì„$',        # ì–‘ë™ë§ˆì„, í•˜íšŒë§ˆì„
            r'\w+í•´ë³€$',        # ì •ë™ì§„í•´ë³€
            r'\w+í•´ìˆ˜ìš•ì¥$',    # í•´ìš´ëŒ€í•´ìˆ˜ìš•ì¥
            r'\w+ìœ ì ì§€$',      # ì›”ì„±ìœ ì ì§€
            r'\w+ì„¼í„°$',        # ë¬¸í™”ì„¼í„°
            r'\w+ì—­$',          # ê¸°ì°¨ì—­
        ]
        
        for pattern in place_patterns:
            if re.search(pattern, text):
                return True
        
        # ë¶€ì ì ˆí•œ ë‹¨ì–´ë“¤ (ì¥ì†Œëª…ì´ ì•„ë‹Œ ê²ƒë“¤)
        non_place_words = [
            'ì—­ì‚¬', 'ë¬¸í™”', 'ì „í†µ', 'ì²´í—˜', 'ê´€ëŒ', 'êµ¬ê²½', 'ì‚°ì±…', 'íƒë°©',
            'ë°©ë¬¸', 'íˆ¬ì–´', 'ì—¬í–‰', 'íœ´ì‹', 'ê°ìƒ', 'ê´€ì°°', 'í•™ìŠµ'
        ]
        
        # ë‹¨ì¼ ë‹¨ì–´ì´ë©´ì„œ ë¶€ì ì ˆí•œ ë‹¨ì–´ì¸ ê²½ìš°
        if text.strip() in non_place_words:
            return False
            
        return True  # ê¸°ë³¸ì ìœ¼ë¡œëŠ” ì¥ì†Œëª…ìœ¼ë¡œ ê°„ì£¼

    def verify_and_enrich_location(self, activity: dict, region: str = None) -> dict:
        """
        í™œë™ ì •ë³´ì˜ ì¥ì†Œë¥¼ ê²€ì¦í•˜ê³  ì •í™•í•œ ì •ë³´ë¡œ ë³´ê°•í•©ë‹ˆë‹¤.
        
        Args:
            activity: í™œë™ ì •ë³´ ë”•ì…”ë„ˆë¦¬
            region: ì§€ì—­ëª… (ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒìš©)
            
        Returns:
            ê²€ì¦ ë° ë³´ê°•ëœ í™œë™ ì •ë³´
        """
        title = activity.get('title', '')
        location = activity.get('location', '')
        
        logger.info(f"ğŸ” ì¥ì†Œ ê²€ì¦ ì‹œì‘: '{title}' (location: '{location}')")
        
        # ê²€ìƒ‰ í‚¤ì›Œë“œ ìš°ì„ ìˆœìœ„ ìƒì„±
        search_keywords = []
        
        # 1. locationì´ êµ¬ì²´ì ì¸ ì¥ì†Œëª…ì´ë©´ ìµœìš°ì„  (ìƒì„¸ì£¼ì†Œê°€ ì•„ë‹Œ ê²½ìš°ë§Œ)
        if location and location.strip() and not self._is_detailed_address(location.strip()):
            # locationì´ ì‹¤ì œ ì¥ì†Œëª…ì¸ì§€ í™•ì¸
            if self._is_real_place_name(location.strip()):
                search_keywords.append(location.strip())
                # locationì—ì„œë„ ë¶ˆí•„ìš”í•œ ë‹¨ì–´ ì œê±°í•œ ë²„ì „
                cleaned_location = self._clean_place_name(location.strip())
                if cleaned_location != location.strip() and cleaned_location not in search_keywords:
                    search_keywords.append(cleaned_location)
        
        # 2. titleì—ì„œ êµ¬ì²´ì ì¸ ì¥ì†Œëª… ì¶”ì¶œ
        extracted_places = self._extract_place_name_from_title(title)
        # locationê³¼ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ê²ƒë§Œ ì¶”ê°€
        for place in extracted_places:
            if place not in search_keywords:
                search_keywords.append(place)
        
        # 3. locationì´ ìƒì„¸ ì£¼ì†Œì¸ ê²½ìš° ì²˜ë¦¬
        if location and location.strip() and self._is_detailed_address(location.strip()):
            # ìƒì„¸ ì£¼ì†ŒëŠ” í›„ìˆœìœ„ë¡œ (ë³´ì¡° ìˆ˜ë‹¨)
            logger.info(f"ìƒì„¸ ì£¼ì†Œ ê°ì§€, í›„ìˆœìœ„ë¡œ ì´ë™: {location.strip()}")
        elif location and location.strip() and not self._is_real_place_name(location.strip()):
            # locationì´ ì¥ì†Œëª…ì´ ì•„ë‹Œ ê²½ìš°ë„ í›„ìˆœìœ„ë¡œ
            logger.info(f"ì¼ë°˜ì ì´ì§€ ì•Šì€ location, í›„ìˆœìœ„ë¡œ ì´ë™: {location.strip()}")
        
        # 3. ì›ë³¸ titleë„ í¬í•¨ (ì¤‘ê°„ ìˆœìœ„)
        if title not in search_keywords:
            search_keywords.append(title)
            
        # 4. ìƒì„¸ ì£¼ì†ŒëŠ” ìµœí›„ ìˆ˜ë‹¨ìœ¼ë¡œë§Œ ì‚¬ìš©
        if location and location.strip() and self._is_detailed_address(location.strip()):
            if location.strip() not in search_keywords:
                search_keywords.append(location.strip())
        
        logger.info(f"ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ ëª©ë¡: {search_keywords}")
        
        # í‚¤ì›Œë“œë³„ë¡œ ìˆœì°¨ ê²€ìƒ‰
        search_result = None
        successful_keyword = None
        
        for keyword in search_keywords:
            if not keyword or len(keyword.strip()) < 2:
                continue
                
            logger.info(f"ğŸ” í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ ì¤‘: '{keyword}'")
            search_result = self.search_place(keyword, region)
            
            if search_result and search_result.get('found'):
                # ê²€ìƒ‰ ê²°ê³¼ì˜ ê´€ë ¨ì„± ê²€ì¦
                if self._is_relevant_result(keyword, search_result, title):
                    successful_keyword = keyword
                    logger.info(f"âœ… ê²€ìƒ‰ ì„±ê³µ: '{keyword}' -> {search_result.get('name')}")
                    break
                else:
                    logger.info(f"âŒ ê²€ìƒ‰ ê²°ê³¼ ê´€ë ¨ì„± ë‚®ìŒ: '{keyword}' -> {search_result.get('name')}")
                    search_result = None
            else:
                logger.info(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: '{keyword}'")
        
        # ê²€ì¦ëœ ì •ë³´ë¡œ í™œë™ ì •ë³´ ì—…ë°ì´íŠ¸
        if search_result and search_result.get('found'):
            activity['verified'] = True
            activity['real_address'] = search_result.get('road_address') or search_result.get('address')
            activity['place_category'] = search_result.get('category')
            activity['place_telephone'] = search_result.get('phone')
            activity['coordinates'] = {
                'lat': float(search_result.get('y', 0)) if search_result.get('y') else None,
                'lng': float(search_result.get('x', 0)) if search_result.get('x') else None
            }
            
            # ì •í™•í•œ ì¥ì†Œëª…ìœ¼ë¡œ ì—…ë°ì´íŠ¸
            if search_result.get('name'):
                activity['verified_name'] = search_result.get('name')
                activity['location'] = search_result.get('road_address') or search_result.get('address') or activity['location']
                
            logger.info(f"ğŸ‰ ì¥ì†Œ ê²€ì¦ ì™„ë£Œ: '{title}' -> '{search_result.get('name')}' (í‚¤ì›Œë“œ: '{successful_keyword}')")
            logger.info(f"   ì£¼ì†Œ: {activity['real_address']}")
            logger.info(f"   ì¹´í…Œê³ ë¦¬: {activity['place_category']}")
        else:
            activity['verified'] = False
            # ê²€ì¦ ì‹¤íŒ¨í•œ ê²½ìš° ê°€ì§œ ì£¼ì†Œ í‘œì‹œ ë°©ì§€
            activity['location'] = f"âš ï¸ {activity.get('location', '')} (ê²€ì¦ë˜ì§€ ì•Šì€ ì£¼ì†Œ)"
            activity['real_address'] = "ê²€ì¦ë˜ì§€ ì•Šì€ ì£¼ì†Œì…ë‹ˆë‹¤"
            logger.warning(f"âš ï¸ ì¥ì†Œ ê²€ì¦ ì‹¤íŒ¨: '{title}' - ëª¨ë“  í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í–ˆì§€ë§Œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            logger.warning(f"   ì‹œë„í•œ í‚¤ì›Œë“œ: {search_keywords}")
            
        return activity

# ========================================
# ì—¬í–‰ ë°ì´í„° ê²€ì¦ ë° ë³´ê°• í•¨ìˆ˜
# ========================================
async def verify_and_enrich_trip_data(trip_data: dict, kakao_service: KakaoLocalService, destination: str) -> dict:
    """
    ì—¬í–‰ ê³„íš ë°ì´í„°ì˜ ëª¨ë“  ì¥ì†Œë¥¼ ì¹´ì¹´ì˜¤ APIë¡œ ê²€ì¦í•˜ê³  ë³´ê°•í•©ë‹ˆë‹¤.
    ê²€ì¦ì— ì‹¤íŒ¨í•œ ì¥ì†Œê°€ ìˆìœ¼ë©´ í•´ë‹¹ í™œë™ë§Œ ë‹¤ì‹œ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if not trip_data.get("itinerary"):
        return trip_data
    
    failed_activities = []
    region = destination.split()[0]  # ì§€ì—­ëª… ì¶”ì¶œ (ì˜ˆ: "ë¶€ì‚° í•´ìš´ëŒ€" -> "ë¶€ì‚°")
    
    # ê° ì¼ì°¨ë³„ë¡œ í™œë™ ê²€ì¦
    for day_idx, day in enumerate(trip_data["itinerary"]):
        if not day.get("activities"):
            continue
            
        for activity_idx, activity in enumerate(day["activities"]):
            # í˜¸í…”/ìˆ™ë°• ê´€ë ¨ í™œë™ì€ ê²€ì¦í•˜ì§€ ì•ŠìŒ
            title = activity.get('title', '').lower()
            if any(keyword in title for keyword in ['í˜¸í…”', 'ìˆ™ë°•', 'ì²´í¬ì¸', 'ì²´í¬ì•„ì›ƒ', 'hotel', 'check-in', 'check-out']):
                continue
            
            # ì¹´ì¹´ì˜¤ APIë¡œ ì¥ì†Œ ê²€ì¦ ë° ë³´ê°•
            verified_activity = kakao_service.verify_and_enrich_location(activity, region)
            
            # ê²€ì¦ ì‹¤íŒ¨í•œ í™œë™ ê¸°ë¡
            if not verified_activity.get('verified', False):
                failed_activities.append({
                    'day_idx': day_idx,
                    'activity_idx': activity_idx,
                    'day': day.get('day'),
                    'original_activity': activity.copy()
                })
            
            # ê²€ì¦ëœ ì •ë³´ë¡œ ì—…ë°ì´íŠ¸
            day["activities"][activity_idx] = verified_activity
    
    # ê²€ì¦ ì‹¤íŒ¨í•œ í™œë™ì´ ìˆìœ¼ë©´ ì¬ìƒì„±
    if failed_activities:
        logger.info(f"ê²€ì¦ ì‹¤íŒ¨í•œ í™œë™ {len(failed_activities)}ê°œë¥¼ ì¬ìƒì„±í•©ë‹ˆë‹¤...")
        trip_data = await regenerate_failed_activities(trip_data, failed_activities, destination)
        
        # ì¬ìƒì„± í›„ ì¤‘ë³µ ì²´í¬ ë° ì œê±°
        logger.info("ì¬ìƒì„± í›„ ì¤‘ë³µ ì¥ì†Œ ì¬ê²€ì‚¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        trip_data = await remove_duplicate_locations(trip_data, destination)
    
    return trip_data

async def regenerate_failed_activities(trip_data: dict, failed_activities: list, destination: str) -> dict:
    """
    ê²€ì¦ì— ì‹¤íŒ¨í•œ í™œë™ë“¤ì„ OpenAIë¡œ ë‹¤ì‹œ ìƒì„±í•©ë‹ˆë‹¤.
    """
    for failed in failed_activities:
        day_idx = failed['day_idx']
        activity_idx = failed['activity_idx']
        day_num = failed['day']
        original = failed['original_activity']
        
        try:
            # í•´ë‹¹ ì¼ì°¨ì˜ ë‹¤ë¥¸ í™œë™ë“¤ ì •ë³´ ìˆ˜ì§‘
            day_activities = trip_data["itinerary"][day_idx]["activities"]
            other_activities = [act for i, act in enumerate(day_activities) if i != activity_idx]
            
            # ì „ì²´ ì—¬í–‰ ì¼ì •ì—ì„œ ì´ë¯¸ ì‚¬ìš©ëœ ëª¨ë“  ì¥ì†Œë“¤ ìˆ˜ì§‘ (ì¤‘ë³µ ë°©ì§€)
            all_used_locations = []
            for day_data in trip_data.get("itinerary", []):
                for activity in day_data.get("activities", []):
                    if activity.get('title') and activity.get('location'):
                        all_used_locations.append({
                            "title": activity.get('title'),
                            "location": activity.get('location'),
                            "day": day_data.get('day')
                        })
            
            # ì¬ìƒì„± í”„ë¡¬í”„íŠ¸
            regeneration_prompt = f"""Replace failed activity "{original.get('title', '')}" with real {destination} tourist spot.

ğŸš¨ **NO DUPLICATES**: Don't use these already used places:
{json.dumps(all_used_locations, ensure_ascii=False, indent=2)}

Current day {day_num} activities:
{json.dumps(other_activities, ensure_ascii=False, indent=2)}

ğŸš¨ **RULES**:
1. **NO duplicates with listed places above** - TOP PRIORITY!
2. **Use only real famous tourist spots** - NO fake places
3. Choose only famous landmarks in {destination}
4. Don't use uncertain addresses or places
5. Keep similar time as original ({original.get('time', '')})
6. **Use specific proper nouns**:
   âŒ Wrong: "beach walk", "market tour", "park visit"
   âœ… Correct: "Haeundae Beach", "Jagalchi Market", "Namsan Park"
7. location field: famous tourist spot names only
8. Return single activity object in JSON format

**{destination} famous spots**:
- Busan: Haeundae Beach, Gwangalli Beach, Jagalchi Market, Gamcheon Culture Village, Taejongdae
- Seoul: Gyeongbokgung Palace, N Seoul Tower, Myeongdong, Insadong, Han River Park
- Jeju: Seongsan Ilchulbong, Hallasan, Cheonjiyeon Falls, Hyeopjae Beach

ğŸ”‘ **IMPORTANT: location vs title fields**
- **location**: actual place name only (e.g., "Haeundae Beach", "Jagalchi Market")
- **title**: display activity name (e.g., "Haeundae walk", "Jagalchi market tour")

JSON format:
{{
    "time": "time",
    "title": "activity name (e.g., Haeundae walk)",
    "location": "actual place name only (e.g., Haeundae Beach)",
    "description": "activity description",
    "duration": "duration"
}}
"""
            
            # OpenAI API í˜¸ì¶œ
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "You are a Korean tourism expert. Replace failed fake places with real famous tourist spots. ğŸš¨ TOP RULE: NO duplicates with already used places! Don't create fake addresses or non-existent places. Use only famous landmarks you're certain about."},
                    {"role": "user", "content": regeneration_prompt}
                ],
                max_tokens=500,
                temperature=0.3  # ë” ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´ ì˜¨ë„ ê°ì†Œ
            )
            
            content = response.choices[0].message.content.strip()
            
            # JSON íŒŒì‹±
            start_idx = content.find('{')
            end_idx = content.rfind('}') + 1
            if start_idx != -1 and end_idx != -1:
                json_str = content[start_idx:end_idx]
                new_activity = json.loads(json_str)
                
                # ìƒˆë¡œìš´ í™œë™ìœ¼ë¡œ êµì²´
                trip_data["itinerary"][day_idx]["activities"][activity_idx] = new_activity
                logger.info(f"{day_num}ì¼ì°¨ í™œë™ ì¬ìƒì„± ì™„ë£Œ: {original.get('title')} -> {new_activity.get('title')}")
                
                # ì¬ìƒì„±ëœ í™œë™ì´ ë‹¤ë¥¸ ë‚ ì§œì™€ ì¤‘ë³µë˜ëŠ”ì§€ ì¦‰ì‹œ ì²´í¬
                new_title = new_activity.get('title', '').lower()
                new_location = new_activity.get('location', '').lower()
                
                for check_day_idx, check_day in enumerate(trip_data.get("itinerary", [])):
                    if check_day_idx == day_idx:  # ê°™ì€ ë‚ ì€ ê±´ë„ˆë›°ê¸°
                        continue
                    for check_activity in check_day.get("activities", []):
                        check_title = check_activity.get('title', '').lower()
                        check_location = check_activity.get('location', '').lower()
                        
                        if (new_title and check_title and new_title in check_title) or \
                           (new_location and check_location and new_location in check_location):
                            logger.warning(f"ğŸš¨ ì¬ìƒì„±ëœ í™œë™ì´ ì¤‘ë³µ ì˜ì‹¬: {day_num}ì¼ì°¨ '{new_activity.get('title')}' vs {check_day.get('day')}ì¼ì°¨ '{check_activity.get('title')}'")
                            
            else:
                logger.error(f"{day_num}ì¼ì°¨ í™œë™ ì¬ìƒì„± ì‹¤íŒ¨: JSON íŒŒì‹± ì˜¤ë¥˜")
                
        except Exception as e:
            logger.error(f"{day_num}ì¼ì°¨ í™œë™ ì¬ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    return trip_data

# ========================================
# ì¤‘ë³µ ì¥ì†Œ ì œê±° í•¨ìˆ˜
# ========================================
def _extract_location_keywords(place_name: str, location_name: str) -> list:
    """ì¥ì†Œëª…ì—ì„œ ì¤‘ë³µ ê°ì§€ë¥¼ ìœ„í•œ í‚¤ì›Œë“œë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    keywords = set()
    
    # ë‘ í•„ë“œ ëª¨ë‘ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    for text in [place_name, location_name]:
        if not text:
            continue
            
        # ê¸°ë³¸ ì •ê·œí™” (ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì œê±°)
        normalized = ''.join(text.lower().split())
        keywords.add(normalized)
        
        # ì£¼ìš” ì¥ì†Œ í‚¤ì›Œë“œ ì¶”ì¶œ
        location_keywords = _extract_major_location_keywords(text)
        keywords.update(location_keywords)
        
        # í•µì‹¬ ì¥ì†Œëª… ì¶”ì¶œ (ë” ì •êµí•œ ì¶”ì¶œ)
        core_keywords = _extract_core_location_name(text)
        keywords.update(core_keywords)
    
    return list(filter(None, keywords))

def _extract_core_location_name(text: str) -> set:
    """í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ ì¥ì†Œëª…ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    import re
    keywords = set()
    
    # í…ìŠ¤íŠ¸ ì •ë¦¬
    text = text.lower().strip()
    
    # 1. í•µì‹¬ ì§€ëª… íŒ¨í„´ ì¶”ì¶œ
    core_patterns = [
        r'([ê°€-í£]{2,}í•´ìˆ˜ìš•ì¥|[ê°€-í£]{2,}í•´ë³€)',  # í•´ë³€/í•´ìˆ˜ìš•ì¥
        r'([ê°€-í£]{2,}ì‹œì¥)',                      # ì‹œì¥
        r'([ê°€-í£]{2,}ê¶|[ê°€-í£]{2,}ê¶ê¶)',        # ê¶ê¶
        r'([ê°€-í£]{2,}ì‚¬|[ê°€-í£]{2,}ì ˆ)',          # ì‚¬ì°°
        r'([ê°€-í£]{2,}íƒ€ì›Œ|[ê°€-í£]{2,}íƒ‘)',        # íƒ€ì›Œ/íƒ‘
        r'([ê°€-í£]{2,}ê³µì›)',                      # ê³µì›
        r'([ê°€-í£]{2,}ë°•ë¬¼ê´€)',                    # ë°•ë¬¼ê´€
        r'([ê°€-í£]{2,}ë¯¸ìˆ ê´€)',                    # ë¯¸ìˆ ê´€
        r'([ê°€-í£]{2,}í­í¬)',                      # í­í¬
        r'([ê°€-í£]{2,}ì‚°)',                        # ì‚°
        r'([ê°€-í£]{2,}ë´‰)',                        # ë´‰ìš°ë¦¬
        r'([ê°€-í£]{2,}ë‹¤ë¦¬)',                      # ë‹¤ë¦¬
        r'([ê°€-í£]{2,}í•­|[ê°€-í£]{2,}í¬êµ¬)',        # í•­êµ¬/í¬êµ¬
        r'([ê°€-í£]{2,}ë§ˆì„)',                      # ë§ˆì„
        r'([ê°€-í£]{2,}ê±°ë¦¬|[ê°€-í£]{2,}ê¸¸)',        # ê±°ë¦¬/ê¸¸
        r'([ê°€-í£]{2,}ë™)',                        # ë™ë„¤
        r'([ê°€-í£]{2,}êµ¬)',                        # êµ¬
        r'([ê°€-í£]{2,}ì„¬|[ê°€-í£]{2,}ë„)',          # ì„¬/ë„
    ]
    
    for pattern in core_patterns:
        matches = re.findall(pattern, text)
        for match in matches:
            keywords.add(match)
    
    # 2. ë³µí•© ì§€ëª…ì—ì„œ í•µì‹¬ ë¶€ë¶„ ì¶”ì¶œ
    # ì˜ˆ: "í•´ìš´ëŒ€í•´ìˆ˜ìš•ì¥ ì‚°ì±…" â†’ "í•´ìš´ëŒ€", "í•´ìš´ëŒ€í•´ìˆ˜ìš•ì¥"
    compound_patterns = [
        r'([ê°€-í£]{2,})(í•´ìˆ˜ìš•ì¥|í•´ë³€|ì‹œì¥|ê¶|ì‚¬|íƒ‘|íƒ€ì›Œ|ê³µì›|ë°•ë¬¼ê´€|ë¯¸ìˆ ê´€)',
        r'([ê°€-í£]{2,})(ë¬¸í™”ë§ˆì„|ê´€ê´‘ì§€|ì „ë§ëŒ€|ì¼€ì´ë¸”ì¹´)',
    ]
    
    for pattern in compound_patterns:
        matches = re.findall(pattern, text)
        for match in matches:
            if len(match) == 2:  # (ì§€ëª…, ì‹œì„¤ëª…) íŠœí”Œ
                keywords.add(match[0])  # ì§€ëª… ë¶€ë¶„
                keywords.add(match[0] + match[1])  # ì „ì²´ ì´ë¦„
    
    # 3. ìœ ëª… ê´€ê´‘ì§€ì˜ ë³„ì¹­/ì¶•ì•½í˜• ì²˜ë¦¬
    aliases = {
        'í•´ìš´ëŒ€': 'í•´ìš´ëŒ€í•´ìˆ˜ìš•ì¥',
        'ê´‘ì•ˆë¦¬': 'ê´‘ì•ˆë¦¬í•´ìˆ˜ìš•ì¥',
        'ê²½í¬ëŒ€': 'ê²½í¬í•´ë³€',
        'ë‚¨ì‚°': 'ë‚¨ì‚°íƒ€ì›Œ',
        'ìê°ˆì¹˜': 'ìê°ˆì¹˜ì‹œì¥',
        'ë™ëŒ€ë¬¸': 'ë™ëŒ€ë¬¸ë””ìì¸í”Œë¼ì',
        'ëª…ë™': 'ëª…ë™ê±°ë¦¬',
        'í™ëŒ€': 'í™ëŒ€ê±°ë¦¬',
        'ê°•ë‚¨': 'ê°•ë‚¨ì—­',
        'ì´íƒœì›': 'ì´íƒœì›ê±°ë¦¬',
    }
    
    for alias, full_name in aliases.items():
        if alias in text:
            keywords.add(alias)
            keywords.add(full_name)
    
    return keywords

def _extract_major_location_keywords(text: str) -> set:
    """í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” ì¥ì†Œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    import re
    keywords = set()
    
    # ì£¼ìš” ê´€ê´‘ì§€ íŒ¨í„´ë“¤
    patterns = [
        r'([ê°€-í£]{2,}ì¼€ì´ë¸”ì¹´)',     # í•´ìƒì¼€ì´ë¸”ì¹´, ë‚¨ì‚°ì¼€ì´ë¸”ì¹´
        r'([ê°€-í£]{2,}ë„)',          # ì˜¤ë™ë„, ì œì£¼ë„
        r'([ê°€-í£]{2,}í•´ìˆ˜ìš•ì¥)',    # í•´ìš´ëŒ€í•´ìˆ˜ìš•ì¥
        r'([ê°€-í£]{2,}í•´ë³€)',        # ê²½í¬í•´ë³€
        r'([ê°€-í£]{2,}í­í¬)',        # ì²œì§€ì—°í­í¬
        r'([ê°€-í£]{2,}ê³µì›)',        # ë‚¨ì‚°ê³µì›
        r'([ê°€-í£]{2,}ì‹œì¥)',        # ìê°ˆì¹˜ì‹œì¥
        r'([ê°€-í£]{2,}ë°•ë¬¼ê´€)',      # êµ­ë¦½ì¤‘ì•™ë°•ë¬¼ê´€
        r'([ê°€-í£]{2,}ë¯¸ìˆ ê´€)',      # êµ­ë¦½í˜„ëŒ€ë¯¸ìˆ ê´€
        r'([ê°€-í£]{2,}ì‚¬)',          # ë¶ˆêµ­ì‚¬
        r'([ê°€-í£]{2,}ê¶)',          # ê²½ë³µê¶
        r'([ê°€-í£]{2,}ì„±)',          # ìˆ˜ì›í™”ì„±
        r'([ê°€-í£]{2,}íƒ‘)',          # ë‚¨ì‚°íƒ€ì›Œ
        r'([ê°€-í£]{2,}ë‹¤ë¦¬)',        # ê´‘ì•ˆëŒ€êµ
        r'([ê°€-í£]{2,}í•­)',          # ë¶€ì‚°í•­
        r'([ê°€-í£]{2,}ì—­)',          # ì„œìš¸ì—­
        r'([ê°€-í£]{2,}í„°ë¯¸ë„)',      # ê³ ì†í„°ë¯¸ë„
        r'([ê°€-í£]{2,}ì „ë§ëŒ€)',      # ë¶€ì‚°íƒ€ì›Œì „ë§ëŒ€
        r'([ê°€-í£]{2,}ì•„ì¿ ì•„ë¦¬ì›€)',  # ì½”ì—‘ìŠ¤ì•„ì¿ ì•„ë¦¬ì›€
        r'([ê°€-í£]{2,}í…Œë§ˆíŒŒí¬)',    # ì—ë²„ëœë“œí…Œë§ˆíŒŒí¬
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, text)
        for match in matches:
            keywords.add(match.lower())
    
    # íŠ¹ë³„í•œ ê´€ê´‘ì§€ ì¡°í•© ì²˜ë¦¬ (ì—°ê²°ëœ ê´€ê´‘ì§€ë“¤)
    special_combinations = {
        # ì—¬ìˆ˜ ê´€ë ¨
        'í•´ìƒì¼€ì´ë¸”ì¹´': ['ì˜¤ë™ë„', 'í•´ìƒì¼€ì´ë¸”ì¹´', 'ì—¬ìˆ˜í•´ìƒì¼€ì´ë¸”ì¹´'],
        'ì˜¤ë™ë„': ['ì˜¤ë™ë„', 'í•´ìƒì¼€ì´ë¸”ì¹´', 'ì—¬ìˆ˜í•´ìƒì¼€ì´ë¸”ì¹´'],
        
        # ì„œìš¸ íƒ€ì›Œ ê´€ë ¨
        'ë‚¨ì‚°íƒ€ì›Œ': ['ë‚¨ì‚°íƒ€ì›Œ', 'nì„œìš¸íƒ€ì›Œ', 'ì„œìš¸íƒ€ì›Œ'],
        'nì„œìš¸íƒ€ì›Œ': ['ë‚¨ì‚°íƒ€ì›Œ', 'nì„œìš¸íƒ€ì›Œ', 'ì„œìš¸íƒ€ì›Œ'],
        'ì„œìš¸íƒ€ì›Œ': ['ë‚¨ì‚°íƒ€ì›Œ', 'nì„œìš¸íƒ€ì›Œ', 'ì„œìš¸íƒ€ì›Œ'],
        
        # ë¶€ì‚° í•´ë³€ ê´€ë ¨
        'í•´ìš´ëŒ€': ['í•´ìš´ëŒ€', 'í•´ìš´ëŒ€í•´ìˆ˜ìš•ì¥', 'í•´ìš´ëŒ€í•´ë³€'],
        'í•´ìš´ëŒ€í•´ìˆ˜ìš•ì¥': ['í•´ìš´ëŒ€', 'í•´ìš´ëŒ€í•´ìˆ˜ìš•ì¥', 'í•´ìš´ëŒ€í•´ë³€'],
        'í•´ìš´ëŒ€í•´ë³€': ['í•´ìš´ëŒ€', 'í•´ìš´ëŒ€í•´ìˆ˜ìš•ì¥', 'í•´ìš´ëŒ€í•´ë³€'],
        'ê´‘ì•ˆë¦¬': ['ê´‘ì•ˆë¦¬', 'ê´‘ì•ˆë¦¬í•´ìˆ˜ìš•ì¥', 'ê´‘ì•ˆë¦¬í•´ë³€'],
        'ê´‘ì•ˆë¦¬í•´ìˆ˜ìš•ì¥': ['ê´‘ì•ˆë¦¬', 'ê´‘ì•ˆë¦¬í•´ìˆ˜ìš•ì¥', 'ê´‘ì•ˆë¦¬í•´ë³€'],
        
        # ë¶€ì‚° ê´€ê´‘ì§€ ê´€ë ¨
        'ìê°ˆì¹˜ì‹œì¥': ['ìê°ˆì¹˜ì‹œì¥', 'ìê°ˆì¹˜'],
        'ê°ì²œë¬¸í™”ë§ˆì„': ['ê°ì²œë¬¸í™”ë§ˆì„', 'ê°ì²œë§ˆì„'],
        'íƒœì¢…ëŒ€': ['íƒœì¢…ëŒ€', 'íƒœì¢…ëŒ€ìœ ì›ì§€'],
        
        # ì œì£¼ ê´€ë ¨
        'ì„±ì‚°ì¼ì¶œë´‰': ['ì„±ì‚°ì¼ì¶œë´‰', 'ì„±ì‚°ë´‰'],
        'í•œë¼ì‚°': ['í•œë¼ì‚°', 'ë°±ë¡ë‹´'],
        'ì²œì§€ì—°í­í¬': ['ì²œì§€ì—°í­í¬', 'ì²œì§€ì—°'],
        
        # ê²½ì£¼ ê´€ë ¨
        'ë¶ˆêµ­ì‚¬': ['ë¶ˆêµ­ì‚¬', 'ì„êµ´ì•”'],
        'ì„êµ´ì•”': ['ë¶ˆêµ­ì‚¬', 'ì„êµ´ì•”'],
        
        # ê°•ë¦‰ ê´€ë ¨
        'ê²½í¬í•´ë³€': ['ê²½í¬í•´ë³€', 'ê²½í¬í•´ìˆ˜ìš•ì¥', 'ê²½í¬ëŒ€'],
        'ê²½í¬í•´ìˆ˜ìš•ì¥': ['ê²½í¬í•´ë³€', 'ê²½í¬í•´ìˆ˜ìš•ì¥', 'ê²½í¬ëŒ€'],
        'ê²½í¬ëŒ€': ['ê²½í¬í•´ë³€', 'ê²½í¬í•´ìˆ˜ìš•ì¥', 'ê²½í¬ëŒ€'],
        
        # ì„œìš¸ ê¶ê¶ ê´€ë ¨
        'ê²½ë³µê¶': ['ê²½ë³µê¶', 'ê´‘í™”ë¬¸'],
        'ì°½ë•ê¶': ['ì°½ë•ê¶', 'ë¹„ì›'],
        
        # ì¸ì‚¬ë™/ëª…ë™ ê´€ë ¨
        'ì¸ì‚¬ë™': ['ì¸ì‚¬ë™', 'ì¸ì‚¬ë™ê±°ë¦¬'],
        'ëª…ë™': ['ëª…ë™', 'ëª…ë™ê±°ë¦¬', 'ëª…ë™ì„±ë‹¹'],
        
        # ê¸°íƒ€ ìœ ëª… ê´€ê´‘ì§€
        'ë¡¯ë°íƒ€ì›Œ': ['ë¡¯ë°íƒ€ì›Œ', 'ë¡¯ë°ì›”ë“œíƒ€ì›Œ', 'ì„œìš¸ìŠ¤ì¹´ì´'],
        '63ë¹Œë”©': ['63ë¹Œë”©', '63ìŠ¤ì¹´ì´ì•„íŠ¸'],
        'ë™ëŒ€ë¬¸': ['ë™ëŒ€ë¬¸', 'ë™ëŒ€ë¬¸ë””ìì¸í”Œë¼ì', 'ddp'],
    }
    
    text_lower = text.lower()
    for key, related_places in special_combinations.items():
        if key in text_lower:
            keywords.update(related_places)
    
    return keywords

def _is_similar_location(keyword1: str, keyword2: str) -> bool:
    """ë‘ ì¥ì†Œ í‚¤ì›Œë“œê°€ ìœ ì‚¬í•œì§€ íŒë‹¨í•©ë‹ˆë‹¤ (ë” ì—„ê²©í•œ ì¤‘ë³µ ê²€ì‚¬)."""
    if not keyword1 or not keyword2:
        return False
    
    # ì™„ì „ ì¼ì¹˜
    if keyword1 == keyword2:
        return True
    
    # í•œìª½ì´ ë‹¤ë¥¸ ìª½ì„ í¬í•¨í•˜ëŠ” ê²½ìš° (ë” ì—„ê²©í•˜ê²Œ - 2ê¸€ì ì´ìƒë¶€í„°)
    if len(keyword1) >= 2 and len(keyword2) >= 2:
        if keyword1 in keyword2 or keyword2 in keyword1:
            return True
    
    # í•µì‹¬ ì§€ëª…ì´ ê°™ì€ì§€ í™•ì¸ (ì˜ˆ: "í•´ìš´ëŒ€í•´ìˆ˜ìš•ì¥"ê³¼ "í•´ìš´ëŒ€ì¹´í˜" - ë‘˜ ë‹¤ í•´ìš´ëŒ€ ì§€ì—­)
    core_locations = _extract_core_location_parts(keyword1, keyword2)
    if core_locations and len(core_locations) > 0:
        return True
    
    # ê³µí†µ ë¶€ë¶„ì´ 60% ì´ìƒì¸ ê²½ìš° (ë” ì—„ê²©í•˜ê²Œ)
    if len(keyword1) >= 3 and len(keyword2) >= 3:
        common_chars = set(keyword1) & set(keyword2)
        similarity = len(common_chars) / max(len(set(keyword1)), len(set(keyword2)))
        if similarity >= 0.6:
            return True
    
    # ìœ ëª… ê´€ê´‘ì§€ì˜ ë‹¤ì–‘í•œ í‘œí˜„ ë°©ì‹ ì²´í¬
    if _is_same_tourist_spot(keyword1, keyword2):
        return True
    
    return False

def _extract_core_location_parts(keyword1: str, keyword2: str) -> set:
    """ë‘ í‚¤ì›Œë“œì—ì„œ ê³µí†µëœ í•µì‹¬ ì§€ì—­ëª…ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    import re
    
    # í•µì‹¬ ì§€ì—­ëª… íŒ¨í„´
    location_patterns = [
        r'([ê°€-í£]{2,})(í•´ìˆ˜ìš•ì¥|í•´ë³€|ì‹œì¥|ê¶|ì‚¬|íƒ‘|íƒ€ì›Œ|ê³µì›|ë°•ë¬¼ê´€|ë¯¸ìˆ ê´€|í­í¬|ì‚°|ë´‰|ë‹¤ë¦¬|í•­|ë§ˆì„|ê±°ë¦¬|ë™|êµ¬|ì„¬|ë„)',
        r'([ê°€-í£]{2,})(ë¬¸í™”ë§ˆì„|ê´€ê´‘ì§€|ì „ë§ëŒ€|ì¼€ì´ë¸”ì¹´|ì•„ì¿ ì•„ë¦¬ì›€|í…Œë§ˆíŒŒí¬)',
    ]
    
    cores1 = set()
    cores2 = set()
    
    for pattern in location_patterns:
        # keyword1ì—ì„œ í•µì‹¬ ì§€ì—­ëª… ì¶”ì¶œ
        matches1 = re.findall(pattern, keyword1)
        for match in matches1:
            if len(match) == 2:
                cores1.add(match[0])  # ì§€ì—­ëª… ë¶€ë¶„ë§Œ
        
        # keyword2ì—ì„œ í•µì‹¬ ì§€ì—­ëª… ì¶”ì¶œ
        matches2 = re.findall(pattern, keyword2)
        for match in matches2:
            if len(match) == 2:
                cores2.add(match[0])  # ì§€ì—­ëª… ë¶€ë¶„ë§Œ
    
    # ê³µí†µ í•µì‹¬ ì§€ì—­ëª… ë°˜í™˜
    return cores1 & cores2

def _is_same_tourist_spot(keyword1: str, keyword2: str) -> bool:
    """ê°™ì€ ê´€ê´‘ì§€ì˜ ë‹¤ë¥¸ í‘œí˜„ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    # ê°™ì€ ê´€ê´‘ì§€ì˜ ë‹¤ì–‘í•œ í‘œí˜„ë“¤
    same_spots = [
        # ì„œìš¸
        {'ë‚¨ì‚°íƒ€ì›Œ', 'nì„œìš¸íƒ€ì›Œ', 'ì„œìš¸íƒ€ì›Œ', 'ë‚¨ì‚°'},
        {'ê²½ë³µê¶', 'ê²½ë³µê¶ê¶ê¶', 'ê²½ë³µê¶ì•'},
        {'ì°½ë•ê¶', 'ì°½ë•ê¶ê¶ê¶', 'ë¹„ì›'},
        {'ëª…ë™', 'ëª…ë™ê±°ë¦¬', 'ëª…ë™ì‡¼í•‘'},
        {'í™ëŒ€', 'í™ëŒ€ê±°ë¦¬', 'í™ìµëŒ€í•™êµì•'},
        {'ì´íƒœì›', 'ì´íƒœì›ê±°ë¦¬', 'ì´íƒœì›ì—­'},
        {'ê°•ë‚¨', 'ê°•ë‚¨ì—­', 'ê°•ë‚¨êµ¬'},
        {'ë™ëŒ€ë¬¸', 'ë™ëŒ€ë¬¸ë””ìì¸í”Œë¼ì', 'ddp'},
        {'ì¸ì‚¬ë™', 'ì¸ì‚¬ë™ê±°ë¦¬', 'ì¸ì‚¬ë™ë¬¸í™”ê±°ë¦¬'},
        
        # ë¶€ì‚°
        {'í•´ìš´ëŒ€', 'í•´ìš´ëŒ€í•´ìˆ˜ìš•ì¥', 'í•´ìš´ëŒ€í•´ë³€', 'í•´ìš´ëŒ€ë¹„ì¹˜'},
        {'ê´‘ì•ˆë¦¬', 'ê´‘ì•ˆë¦¬í•´ìˆ˜ìš•ì¥', 'ê´‘ì•ˆë¦¬í•´ë³€', 'ê´‘ì•ˆë¦¬ë¹„ì¹˜'},
        {'ìê°ˆì¹˜ì‹œì¥', 'ìê°ˆì¹˜', 'ìê°ˆì¹˜ìˆ˜ì‚°ì‹œì¥'},
        {'ê°ì²œë¬¸í™”ë§ˆì„', 'ê°ì²œë§ˆì„', 'ê°ì²œìƒ‰ê¹”ë§ˆì„'},
        {'íƒœì¢…ëŒ€', 'íƒœì¢…ëŒ€ìœ ì›ì§€', 'íƒœì¢…ëŒ€ê³µì›'},
        {'ë¶€ì‚°íƒ€ì›Œ', 'ë¶€ì‚°íƒ€ì›Œì „ë§ëŒ€', 'ìš©ë‘ì‚°ê³µì›íƒ€ì›Œ'},
        {'êµ­ì œì‹œì¥', 'ë¶€ì‚°êµ­ì œì‹œì¥', 'êµ­ì œì‹œì¥ê±°ë¦¬'},
        
        # ì œì£¼
        {'ì„±ì‚°ì¼ì¶œë´‰', 'ì„±ì‚°ë´‰', 'ì¼ì¶œë´‰'},
        {'í•œë¼ì‚°', 'ë°±ë¡ë‹´', 'í•œë¼ì‚°ë°±ë¡ë‹´'},
        {'ì²œì§€ì—°í­í¬', 'ì²œì§€ì—°', 'ì²œì§€ì—°ê³„ê³¡'},
        {'í˜‘ì¬í•´ìˆ˜ìš•ì¥', 'í˜‘ì¬í•´ë³€', 'í˜‘ì¬ë¹„ì¹˜'},
        {'ìš°ë„', 'ìš°ë„ì„¬', 'ì†Œê°€ì„¬'},
        
        # ê°•ë¦‰
        {'ê²½í¬í•´ë³€', 'ê²½í¬í•´ìˆ˜ìš•ì¥', 'ê²½í¬ëŒ€', 'ê²½í¬ëŒ€í•´ë³€'},
        {'ì •ë™ì§„', 'ì •ë™ì§„í•´ë³€', 'ì •ë™ì§„ì—­'},
        {'ì˜¤ì£½í—Œ', 'ìœ¨ê³¡ì´ì´ìƒê°€', 'ì‹ ì‚¬ì„ë‹¹ìƒê°€'},
        
        # ì—¬ìˆ˜
        {'ì˜¤ë™ë„', 'ë™ë°±ì„¬', 'ì˜¤ë™ë„ê³µì›'},
        {'ì—¬ìˆ˜í•´ìƒì¼€ì´ë¸”ì¹´', 'í•´ìƒì¼€ì´ë¸”ì¹´', 'ëŒì‚°ì¼€ì´ë¸”ì¹´'},
        {'ì—¬ìˆ˜ë°¤ë°”ë‹¤', 'ì—¬ìˆ˜í•­', 'ì—¬ìˆ˜ì‹ í•­'},
        
        # ê²½ì£¼
        {'ë¶ˆêµ­ì‚¬', 'ë¶ˆêµ­ì‚¬ì ˆ', 'ë¶ˆêµ­ì‚¬ì‚¬ì°°'},
        {'ì„êµ´ì•”', 'ì„êµ´ì•”ì„êµ´', 'ì„êµ´ì•”ë¶ˆìƒ'},
        {'ì²¨ì„±ëŒ€', 'ê²½ì£¼ì²¨ì„±ëŒ€', 'ì‹ ë¼ì²¨ì„±ëŒ€'},
        {'ì•ˆì••ì§€', 'ë™ê¶ê³¼ì›”ì§€', 'ê²½ì£¼ì•ˆì••ì§€'},
    ]
    
    for spot_group in same_spots:
        if keyword1 in spot_group and keyword2 in spot_group:
            return True
    
    return False

async def remove_duplicate_locations(trip_data: dict, destination: str) -> dict:
    """
    ì—¬í–‰ ê³„íšì—ì„œ ì¤‘ë³µë˜ëŠ” ì¥ì†Œë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ê°ì§€í•˜ê³  ì¦‰ì‹œ êµì²´í•©ë‹ˆë‹¤.
    ë” íš¨ìœ¨ì ì¸ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì¤‘ë³µ ë°œê²¬ ì‹œ ë°”ë¡œ êµì²´í•©ë‹ˆë‹¤.
    """
    if not trip_data.get("itinerary"):
        return trip_data
    
    visited_locations = set()
    fixed_count = 0
    
    # 1ì¼ì°¨ë¶€í„° ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬
    for day_idx, day in enumerate(trip_data["itinerary"]):
        if not day.get("activities"):
            continue
        
        day_num = day.get('day', day_idx + 1)
        logger.info(f"{day_num}ì¼ì°¨ ì¤‘ë³µ ê²€ì‚¬ ì‹œì‘...")
            
        for activity_idx, activity in enumerate(day["activities"]):
            # í˜¸í…”/ìˆ™ë°• ê´€ë ¨ í™œë™ì€ ì²´í¬í•˜ì§€ ì•ŠìŒ
            title = activity.get('title', '').lower()
            if any(keyword in title for keyword in ['í˜¸í…”', 'ìˆ™ë°•', 'ì²´í¬ì¸', 'ì²´í¬ì•„ì›ƒ', 'hotel', 'check-in', 'check-out']):
                continue
            
            # ì¥ì†Œëª…ìœ¼ë¡œ ì¤‘ë³µ ì²´í¬
            place_name = activity.get('title', '').strip()
            location_name = activity.get('location', '').strip()
            
            # ë” ì •êµí•œ ì¤‘ë³µ ê°ì§€ë¥¼ ìœ„í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
            location_keys = _extract_location_keywords(place_name, location_name)
            
            # ì¤‘ë³µ ì²´í¬
            is_duplicate = False
            duplicate_key = None
            
            for key in location_keys:
                if key and key in visited_locations:
                    is_duplicate = True
                    duplicate_key = key
                    break
                    
                # ê¸°ì¡´ ë°©ë¬¸ ì¥ì†Œë“¤ê³¼ ìœ ì‚¬ì„± ê²€ì‚¬
                for visited_key in visited_locations:
                    if _is_similar_location(key, visited_key):
                        is_duplicate = True
                        duplicate_key = key
                        break
                        
                if is_duplicate:
                    break
            
            if is_duplicate:
                # ì¤‘ë³µ ë°œê²¬ ì‹œ ì¦‰ì‹œ êµì²´
                logger.info(f"ğŸ”„ ì¤‘ë³µ ì¥ì†Œ ì¦‰ì‹œ êµì²´: {day_num}ì¼ì°¨ '{place_name}' (í‚¤ì›Œë“œ: {duplicate_key})")
                
                # ë‹¨ì¼ í™œë™ êµì²´
                new_activity = await replace_single_duplicate_activity(
                    trip_data, day_idx, activity_idx, destination, visited_locations
                )
                
                if new_activity:
                    # êµì²´ ì „í›„ ì •ë³´ ë¡œê¹…
                    original_location = activity.get('location', 'N/A')
                    new_title = new_activity.get('title', 'N/A')
                    new_location = new_activity.get('location', 'N/A')
                    new_real_address = new_activity.get('real_address', 'N/A')
                    
                    logger.info(f"ğŸ”„ ì¥ì†Œ êµì²´ ìƒì„¸:")
                    logger.info(f"   ì´ì „: '{place_name}' -> {original_location}")
                    logger.info(f"   ì´í›„: '{new_title}' -> {new_location}")
                    if new_activity.get('verified'):
                        logger.info(f"   ê²€ì¦ëœ ì£¼ì†Œ: {new_real_address}")
                    
                    trip_data["itinerary"][day_idx]["activities"][activity_idx] = new_activity
                    fixed_count += 1
                    
                    # ìƒˆë¡œìš´ í™œë™ì˜ í‚¤ì›Œë“œë¥¼ ë°©ë¬¸ ëª©ë¡ì— ì¶”ê°€
                    new_location_keys = _extract_location_keywords(
                        new_activity.get('title', ''), 
                        new_activity.get('location', '')
                    )
                    for key in new_location_keys:
                        if key:
                            visited_locations.add(key)
                    
                    logger.info(f"âœ… êµì²´ ì™„ë£Œ: {place_name} â†’ {new_activity.get('title')}")
                else:
                    # êµì²´ ì‹¤íŒ¨ ì‹œ ì›ë˜ í™œë™ì˜ í‚¤ì›Œë“œë¥¼ ì¶”ê°€ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
                    for key in location_keys:
                        if key:
                            visited_locations.add(key)
            else:
                # ì¤‘ë³µì´ ì•„ë‹Œ ê²½ìš° ëª¨ë“  í‚¤ì›Œë“œë¥¼ ë°©ë¬¸ ëª©ë¡ì— ì¶”ê°€
                for key in location_keys:
                    if key:
                        visited_locations.add(key)
    
    if fixed_count > 0:
        logger.info(f"âœ… ì´ {fixed_count}ê°œì˜ ì¤‘ë³µ ì¥ì†Œë¥¼ êµì²´í–ˆìŠµë‹ˆë‹¤.")
    else:
        logger.info("âœ… ì¤‘ë³µ ì¥ì†Œê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    return trip_data

async def replace_single_duplicate_activity(trip_data: dict, day_idx: int, activity_idx: int, destination: str, visited_locations: set) -> dict:
    """
    ë‹¨ì¼ ì¤‘ë³µ í™œë™ì„ ë¹ ë¥´ê²Œ êµì²´í•©ë‹ˆë‹¤.
    """
    try:
        day = trip_data["itinerary"][day_idx]
        original = day["activities"][activity_idx]
        day_num = day.get('day', day_idx + 1)
        
        # ì´ë¯¸ ì‚¬ìš©ëœ ëª¨ë“  ì¥ì†Œ ëª©ë¡ ìƒì„± (ê°„ì†Œí™”)
        used_titles = set()
        used_locations = set()
        
        for d in trip_data.get("itinerary", []):
            for act in d.get("activities", []):
                if act.get('title'):
                    used_titles.add(act.get('title').lower())
                if act.get('location'):
                    used_locations.add(act.get('location').lower())
        
        # ë¹ ë¥¸ êµì²´ìš© í”„ë¡¬í”„íŠ¸ (ê°„ì†Œí™”)
        replacement_prompt = f"""Replace duplicate "{original.get('title', '')}" activity with different famous {destination} tourist spot.

ğŸš¨ **BANNED PLACES** (already used):
{', '.join(list(used_titles)[:10])}...

**REQUIREMENTS**:
1. Use only real famous tourist spots in {destination}
2. New place that doesn't overlap with listed places above
3. Return single activity in JSON format

ğŸ”‘ **IMPORTANT: location vs title fields**
- **location**: actual place name only (e.g., "Gwangalli Beach", "Gukje Market")
- **title**: display activity name (e.g., "Gwangalli walk", "Gukje market tour")

{{
    "time": "{original.get('time', '09:00')}",
    "title": "new activity name (e.g., Gwangalli walk)",
    "location": "actual place name only (e.g., Gwangalli Beach)",
    "description": "activity description"
}}
"""
        
        # OpenAI API í˜¸ì¶œ (ë” ë¹ ë¥¸ ì„¤ì •)
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": f"You are a {destination} tourism expert. Quickly replace duplicate places with different famous tourist spots. Respond simply and quickly."},
                {"role": "user", "content": replacement_prompt}
            ],
            max_tokens=300,  # í† í° ìˆ˜ ì¤„ì„
            temperature=0.2   # ë” ì¼ê´€ëœ ê²°ê³¼
        )
        
        content = response.choices[0].message.content.strip()
        
        # JSON íŒŒì‹±
        start_idx = content.find('{')
        end_idx = content.rfind('}') + 1
        if start_idx != -1 and end_idx != -1:
            json_str = content[start_idx:end_idx]
            new_activity = json.loads(json_str)
            
            # ğŸ”¥ ì¤‘ìš”: ìƒˆë¡œìš´ í™œë™ì˜ ì£¼ì†Œë¥¼ ì¹´ì¹´ì˜¤ APIë¡œ ì¦‰ì‹œ ê²€ì¦ ë° ì—…ë°ì´íŠ¸
            region = destination.split()[0] if destination else ""
            verified_activity = kakao_service.verify_and_enrich_location(new_activity, region)
            
            # ê²€ì¦ëœ ì •ë³´ë¡œ ì—…ë°ì´íŠ¸
            if verified_activity.get('verified', False):
                logger.info(f"ğŸ”„ êµì²´ëœ ì¥ì†Œ ì£¼ì†Œ ì—…ë°ì´íŠ¸: '{new_activity.get('title')}' -> {verified_activity.get('real_address', 'N/A')}")
                return verified_activity
            else:
                logger.warning(f"âš ï¸ êµì²´ëœ ì¥ì†Œ '{new_activity.get('title')}'ì˜ ì£¼ì†Œ ê²€ì¦ ì‹¤íŒ¨")
                return new_activity
        
    except Exception as e:
        logger.error(f"ë‹¨ì¼ í™œë™ êµì²´ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    return None

async def check_final_duplicates(trip_data: dict) -> list:
    """
    ìµœì¢… ì¤‘ë³µ ê²€ì‚¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    if not trip_data.get("itinerary"):
        return []
    
    all_locations = []
    duplicates = []
    
    # ëª¨ë“  ì¥ì†Œë¥¼ ìˆ˜ì§‘
    for day_idx, day in enumerate(trip_data["itinerary"]):
        if not day.get("activities"):
            continue
            
        for activity_idx, activity in enumerate(day["activities"]):
            title = activity.get('title', '').strip()
            location = activity.get('location', '').strip()
            
            # í˜¸í…”/ìˆ™ë°• ê´€ë ¨ í™œë™ì€ ì²´í¬í•˜ì§€ ì•ŠìŒ
            if any(keyword in title.lower() for keyword in ['í˜¸í…”', 'ìˆ™ë°•', 'ì²´í¬ì¸', 'ì²´í¬ì•„ì›ƒ', 'hotel', 'check-in', 'check-out']):
                continue
            
            location_info = {
                'day_idx': day_idx,
                'activity_idx': activity_idx,
                'day': day.get('day'),
                'title': title,
                'location': location,
                'keywords': _extract_location_keywords(title, location)
            }
            
            # ê¸°ì¡´ ì¥ì†Œë“¤ê³¼ ì¤‘ë³µ ì²´í¬
            for existing in all_locations:
                # ì œëª©ì´ë‚˜ ìœ„ì¹˜ê°€ ì™„ì „íˆ ê°™ì€ ê²½ìš°
                if title.lower() == existing['title'].lower() or location.lower() == existing['location'].lower():
                    duplicates.append(f"Day {day.get('day')}: '{title}' ì¤‘ë³µ (Day {existing['day']}ì™€ ë™ì¼)")
                    continue
                
                # í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ì„± ì²´í¬
                for keyword in location_info['keywords']:
                    if keyword and keyword in existing['keywords']:
                        duplicates.append(f"Day {day.get('day')}: '{title}' ì¤‘ë³µ í‚¤ì›Œë“œ '{keyword}' (Day {existing['day']}ì™€ ì¤‘ë³µ)")
                        break
            
            all_locations.append(location_info)
    
    return duplicates

async def replace_duplicate_activities(trip_data: dict, duplicates: list, destination: str, visited_locations: set) -> dict:
    """
    ì¤‘ë³µëœ í™œë™ë“¤ì„ ìƒˆë¡œìš´ ì¥ì†Œë¡œ êµì²´í•©ë‹ˆë‹¤.
    """
    for duplicate in duplicates:
        day_idx = duplicate['day_idx']
        activity_idx = duplicate['activity_idx']
        day_num = duplicate['day']
        original = duplicate['original_activity']
        
        try:
            # í•´ë‹¹ ì¼ì°¨ì˜ ë‹¤ë¥¸ í™œë™ë“¤ ì •ë³´ ìˆ˜ì§‘
            day_activities = trip_data["itinerary"][day_idx]["activities"]
            other_activities = [act for i, act in enumerate(day_activities) if i != activity_idx]
            
            # ì´ë¯¸ ë°©ë¬¸í•œ ì¥ì†Œë“¤ ëª©ë¡ ìƒì„±
            visited_list = list(visited_locations)
            
            # ì „ì²´ ì¼ì •ì—ì„œ ì´ë¯¸ ì‚¬ìš©ëœ ëª¨ë“  ì¥ì†Œë“¤ ìˆ˜ì§‘
            all_used_locations = set()
            for day in trip_data.get("itinerary", []):
                for activity in day.get("activities", []):
                    if activity.get('title') and activity.get('location'):
                        # ë” ì •êµí•œ í‚¤ì›Œë“œ ì¶”ì¶œë¡œ ì¤‘ë³µ ë°©ì§€
                        used_keywords = _extract_location_keywords(
                            activity.get('title', ''), 
                            activity.get('location', '')
                        )
                        all_used_locations.update(used_keywords)
            
            # êµì²´ìš© í”„ë¡¬í”„íŠ¸ (ë” ê°•í™”ëœ ë²„ì „)
            replacement_prompt = f"""
ğŸš¨ **DUPLICATE PLACE REPLACEMENT REQUEST** ğŸš¨

"{original.get('title', '')}" activity is duplicated with other dates and needs replacement.
Replace with **completely different new place** in {destination}.

**Current day {day_num} other activities:**
{json.dumps(other_activities, ensure_ascii=False, indent=2)}

**ğŸš« BANNED PLACES (already in schedule):**
{', '.join(sorted(list(all_used_locations))[:20])}
... (total {len(all_used_locations)} places already used)

**âš ï¸ DUPLICATE PREVENTION RULES (VERY IMPORTANT!):**
1. **Choose only places completely different from all listed above**
2. **Similar places also banned**: 
   - If "Haeundae Beach" used â†’ "Haeundae Cafe", "near Haeundae" etc. all banned
   - If "Jagalchi Market" used â†’ "Jagalchi Fish Center", "near Jagalchi" etc. all banned
3. **Different facilities in same area/building also banned**
4. **Choose only different area, different type of place**

**âœ… REPLACEMENT REQUIREMENTS:**
1. Use only real famous tourist spots in {destination}
2. Keep time: {original.get('time', '')}
3. Geographically accessible with other day {day_num} activities
4. **Use specific proper nouns**:
   âŒ "another beach", "new market", "another park"
   âœ… "Songdo Beach", "Gukje Market", "Yongdusan Park"
   âš ï¸ For beaches: use "Beach" instead of "beach"

ğŸ”‘ **IMPORTANT: location vs title fields**
- **location**: actual place name only (e.g., "Taejongdae", "Gamcheon Culture Village")
- **title**: display activity name (e.g., "Taejongdae walk", "Gamcheon tour")

**JSON response format:**
{{
    "time": "{original.get('time', '')}",
    "title": "new activity name (e.g., Taejongdae walk)",
    "location": "actual place name only (e.g., Taejongdae)",
    "description": "description of new activity"
}}

**âš ï¸ WARNING**: Don't use anything even slightly similar to banned places above!
"""
            
            # OpenAI API í˜¸ì¶œ
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": """You are a Korean tourism expert handling duplicate place replacement.

ğŸš¨ **ABSOLUTE RULES**:
1. **NO DUPLICATES**: Don't choose anything even slightly similar to "banned places" list
2. **Similar places also banned**: Different facilities in same area/building also banned (e.g., Haeundae Beach â†’ all Haeundae-related places banned)
3. **Specific proper nouns only**: No vague expressions like "another beach", "new market"
4. **Real existence confirmed**: Choose only famous tourist spots you're certain exist
5. **Completely different area**: Choose only different area, different type of place from existing ones

âš ï¸ If uncertain, don't choose. Recommend only places you're certain about."""},
                    {"role": "user", "content": replacement_prompt}
                ],
                max_tokens=500,
                temperature=0.8  # ë” ë‹¤ì–‘í•œ ê²°ê³¼ë¥¼ ìœ„í•´ ì˜¨ë„ ì¦ê°€
            )
            
            content = response.choices[0].message.content.strip()
            
            # JSON íŒŒì‹±
            start_idx = content.find('{')
            end_idx = content.rfind('}') + 1
            if start_idx != -1 and end_idx != -1:
                json_str = content[start_idx:end_idx]
                new_activity = json.loads(json_str)
                
                # êµì²´ëœ ì¥ì†Œê°€ ë˜ ë‹¤ë¥¸ ì¤‘ë³µì´ ì•„ë‹Œì§€ ê²€ì¦
                new_keywords = _extract_location_keywords(
                    new_activity.get('title', ''), 
                    new_activity.get('location', '')
                )
                
                # ê¸°ì¡´ ì¥ì†Œë“¤ê³¼ ì¤‘ë³µ í™•ì¸
                is_still_duplicate = False
                for new_keyword in new_keywords:
                    if new_keyword in all_used_locations:
                        is_still_duplicate = True
                        logger.warning(f"êµì²´ëœ ì¥ì†Œë„ ì¤‘ë³µë¨: {new_keyword}")
                        break
                    
                    # ë” ì •êµí•œ ìœ ì‚¬ì„± ê²€ì‚¬
                    for used_keyword in all_used_locations:
                        if _is_similar_location(new_keyword, used_keyword):
                            is_still_duplicate = True
                            logger.warning(f"êµì²´ëœ ì¥ì†Œê°€ ìœ ì‚¬í•¨: {new_keyword} â‰ˆ {used_keyword}")
                            break
                    
                    if is_still_duplicate:
                        break
                
                if not is_still_duplicate:
                    # ìƒˆë¡œìš´ í™œë™ìœ¼ë¡œ êµì²´
                    trip_data["itinerary"][day_idx]["activities"][activity_idx] = new_activity
                    
                    # ìƒˆë¡œìš´ ì¥ì†Œë¥¼ ë°©ë¬¸ ëª©ë¡ì— ì¶”ê°€
                    visited_locations.update(new_keywords)
                    
                    logger.info(f"âœ… {day_num}ì¼ì°¨ ì¤‘ë³µ ì¥ì†Œ êµì²´ ì™„ë£Œ: {original.get('title')} -> {new_activity.get('title')}")
                else:
                    # ì—¬ì „íˆ ì¤‘ë³µì´ë©´ ì›ë³¸ ìœ ì§€í•˜ê³  ê²½ê³ 
                    logger.error(f"âŒ {day_num}ì¼ì°¨ êµì²´ ì‹¤íŒ¨ - ìƒˆ ì¥ì†Œë„ ì¤‘ë³µë¨: {new_activity.get('title')}")
                    logger.info(f"ì›ë³¸ í™œë™ ìœ ì§€: {original.get('title')}")
            else:
                logger.error(f"{day_num}ì¼ì°¨ ì¤‘ë³µ ì¥ì†Œ êµì²´ ì‹¤íŒ¨: JSON íŒŒì‹± ì˜¤ë¥˜")
                
        except Exception as e:
            logger.error(f"{day_num}ì¼ì°¨ ì¤‘ë³µ ì¥ì†Œ êµì²´ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    return trip_data

# ========================================
# ë¡œê¹… ì„¤ì • (ë¡œê·¸: í”„ë¡œê·¸ë¨ ì‹¤í–‰ ê³¼ì •ì„ ê¸°ë¡í•˜ëŠ” ê²ƒ)
# ========================================
logging.basicConfig(level=logging.INFO)  # INFO ë ˆë²¨ ì´ìƒì˜ ë¡œê·¸ë¥¼ ëª¨ë‘ ê¸°ë¡
logger = logging.getLogger(__name__)  # í˜„ì¬ íŒŒì¼ì˜ ë¡œê±°ë¥¼ ìƒì„±

# ========================================
# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
# ========================================
# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤

# OpenAI API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤
# API í‚¤ëŠ” AI ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë¹„ë°€ë²ˆí˜¸ ê°™ì€ ê²ƒì…ë‹ˆë‹¤
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    logger.error("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")

# ì¹´ì¹´ì˜¤ ë¡œì»¬ API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤
kakao_api_key = os.getenv("KAKAO_API_KEY")
if not kakao_api_key:
    logger.warning("KAKAO_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¥ì†Œ ê²€ì¦ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")

# OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤ (ìµœì‹  ë²„ì „ í˜¸í™˜)
client = openai.OpenAI(api_key=openai_api_key)

# ========================================
# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
# ========================================
# FastAPIëŠ” í˜„ëŒ€ì ì¸ Python ì›¹ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤
app = FastAPI(title="ì—¬í–‰ í”Œë˜ë„ˆ AI", version="1.0.0")

# ========================================
# CORS ì„¤ì • (Cross-Origin Resource Sharing)
# ========================================
# CORSëŠ” ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ë‹¤ë¥¸ ë„ë©”ì¸ì˜ ì„œë²„ì— ì ‘ê·¼í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ì„¤ì •ì…ë‹ˆë‹¤
# í”„ë¡ íŠ¸ì—”ë“œ(localhost:3000)ì—ì„œ ë°±ì—”ë“œ(localhost:8000)ì— ì ‘ê·¼í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",  # ë¡œì»¬ ê°œë°œìš©
        "https://planner-kq3e.onrender.com",  # Render í”„ë¡ íŠ¸ì—”ë“œ
        "https://trip-planner-frontend.vercel.app",   # Vercel í”„ë¡ íŠ¸ì—”ë“œ (ëŒ€ì•ˆ)
    ],
    allow_credentials=True,  # ì¿ í‚¤ ë“± ì¸ì¦ ì •ë³´ í—ˆìš©
    allow_methods=["*"],  # ëª¨ë“  HTTP ë©”ì„œë“œ í—ˆìš© (GET, POST ë“±)
    allow_headers=["*"],  # ëª¨ë“  í—¤ë” í—ˆìš©
)

# ========================================
# ë°ì´í„° ëª¨ë¸ ì •ì˜ (Pydantic ì‚¬ìš©)
# ========================================
# Pydanticì€ ë°ì´í„° ê²€ì¦ì„ ìë™ìœ¼ë¡œ í•´ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤

class TripRequest(BaseModel):
    """ì—¬í–‰ ê³„íš ìš”ì²­ì„ ë°›ëŠ” ë°ì´í„° ëª¨ë¸"""
    destination: str  # ëª©ì ì§€ (ì˜ˆ: "ì œì£¼ë„", "ë„ì¿„")
    
    start_date: str  # ì‹œì‘ ë‚ ì§œ (ì˜ˆ: "2024-01-01")
    end_date: str    # ì¢…ë£Œ ë‚ ì§œ (ì˜ˆ: "2024-01-03")
    budget: Optional[str] = "ë³´í†µ"  # ì˜ˆì‚° (ì„ íƒì‚¬í•­, ê¸°ë³¸ê°’: "ë³´í†µ")
    interests: Optional[List[str]] = []  # ê´€ì‹¬ì‚¬ ë¦¬ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­, ê¸°ë³¸ê°’: ë¹ˆ ë¦¬ìŠ¤íŠ¸)
    guests: Optional[int] = 2  # íˆ¬ìˆ™ê° ìˆ˜ (ì„ íƒì‚¬í•­, ê¸°ë³¸ê°’: 2ëª…)
    companionType: Optional[str] = ""  # ë™ë°˜ì ìœ í˜• (ì—°ì¸, ì¹œêµ¬, ê°€ì¡± ë“±)
    rooms: Optional[int] = 1   # ê°ì‹¤ ìˆ˜ (ì„ íƒì‚¬í•­, ê¸°ë³¸ê°’: 1ê°œ)
    travelStyle: Optional[str] = ""  # ì—¬í–‰ ìŠ¤íƒ€ì¼
    travelPace: Optional[str] = ""  # ì—¬í–‰ í˜ì´ìŠ¤ (íƒ€ì´íŠ¸í•˜ê²Œ, ë„ë„í•˜ê²Œ)

class ChatModifyRequest(BaseModel):
    """ì±„íŒ…ì„ í†µí•œ ì¼ì • ìˆ˜ì • ìš”ì²­ ë°ì´í„° ëª¨ë¸"""
    message: str  # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ìˆ˜ì • ìš”ì²­ ë©”ì‹œì§€
    current_trip_plan: dict  # í˜„ì¬ ì—¬í–‰ ê³„íš ì „ì²´ ë°ì´í„°

class HotelInfo(BaseModel):
    """í˜¸í…” ì •ë³´ë¥¼ ë‹´ëŠ” ë°ì´í„° ëª¨ë¸"""
    name: str  # í˜¸í…” ì´ë¦„
    type: str  # í˜¸í…” íƒ€ì… (í˜¸í…”, íœì…˜, ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤ ë“±)
    price_range: str  # ê°€ê²©ëŒ€ (ì €ì˜ˆì‚°, ë³´í†µ, ê³ ê¸‰, ëŸ­ì…”ë¦¬)
    booking_links: dict  # ê° ì‚¬ì´íŠ¸ë³„ ì˜ˆì•½ ë§í¬
    description: str  # í˜¸í…” ì„¤ëª…
    rating: Optional[float] = None  # í‰ì  (ì„ íƒì‚¬í•­)
    amenities: Optional[List[str]] = []  # í¸ì˜ì‹œì„¤ ë¦¬ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)

class TripPlan(BaseModel):
    """ì™„ì„±ëœ ì—¬í–‰ ê³„íšì„ ë‹´ëŠ” ë°ì´í„° ëª¨ë¸"""
    destination: str  # ëª©ì ì§€
    duration: str  # ì—¬í–‰ ê¸°ê°„
    itinerary: List[dict]  # ì¼ì •í‘œ (ê° ë‚ ì§œë³„ í™œë™)
    total_cost: str  # ì´ ì˜ˆìƒ ë¹„ìš©
    tips: List[str]  # ì—¬í–‰ íŒ ë¦¬ìŠ¤íŠ¸
    transport_info: Optional[dict] = None  # ëŒ€ì¤‘êµí†µ ì •ë³´
    trip_hotel_search: Optional[dict] = None  # ì „ì²´ ì—¬í–‰ì— ëŒ€í•œ í˜¸í…” ê²€ìƒ‰ ë§í¬
    accommodation: Optional[List[HotelInfo]] = []  # ìˆ™ë°• ì •ë³´ (ì„ íƒì‚¬í•­, ê¸°ë³¸ê°’: ë¹ˆ ë¦¬ìŠ¤íŠ¸)


# ========================================
# ì—¬í–‰ ë¹„ìš© ê³„ì‚° í•¨ìˆ˜
# ========================================

def calculate_trip_cost(budget: str, travel_days: int, destination: str) -> int:
    """ì˜ˆì‚° ë“±ê¸‰ê³¼ ì—¬í–‰ ì¼ìˆ˜ì— ë”°ë¥¸ 1ì¸ë‹¹ ì˜ˆìƒ ë¹„ìš©ì„ ê³„ì‚°í•©ë‹ˆë‹¤"""
    
    # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸
    print(f"ë¹„ìš© ê³„ì‚° - ì˜ˆì‚°: {budget}, ì—¬í–‰ì¼ìˆ˜: {travel_days}, ëª©ì ì§€: {destination}")
    
    # ê¸°ë³¸ ì¼ì¼ ë¹„ìš© (ìˆ™ë°• + ì‹ì‚¬ + êµí†µ + ê´€ê´‘)
    budget_multipliers = {
        "ì €ì˜ˆì‚°": 0.6,    # 60% ìˆ˜ì¤€ (55,800ì›)
        "ë³´í†µ": 1.0,      # 100% ê¸°ì¤€ (93,000ì›)
        "ê³ ê¸‰": 1.5,      # 150% ìˆ˜ì¤€ (139,500ì›)
        "ëŸ­ì…”ë¦¬": 2.2     # 220% ìˆ˜ì¤€ (204,600ì›)
    }
    
    # ì§€ì—­ë³„ ê¸°ë³¸ ë¹„ìš© ì¡°ì • (ì„œìš¸ ê¸°ì¤€ 1.0)
    region_multipliers = {
        # ìˆ˜ë„ê¶Œ
        "ì„œìš¸": 1.3, "ì¸ì²œ": 1.0, "ê²½ê¸°": 1.0,
        # ì œì£¼ë„ (ê´€ê´‘ì§€ í”„ë¦¬ë¯¸ì—„)
        "ì œì£¼": 1.2,
        # ë¶€ì‚°/ëŒ€êµ¬ ë“± ê´‘ì—­ì‹œ
        "ë¶€ì‚°": 1.1, "ëŒ€êµ¬": 0.9, "ê´‘ì£¼": 0.9, "ëŒ€ì „": 0.9, "ìš¸ì‚°": 0.9,
        # ê°•ì›ë„ (ê´€ê´‘ì§€)
        "ê°•ì›": 1.0, "ì¶˜ì²œ": 1.0, "ê°•ë¦‰": 1.1, "ì†ì´ˆ": 1.1, "í‰ì°½": 1.0,
        # ê²½ìƒë„
        "ê²½ì£¼": 0.9, "ì•ˆë™": 0.8, "í¬í•­": 0.9, "ì°½ì›": 0.9, "ì§„ì£¼": 0.8,
        # ì „ë¼ë„
        "ì „ì£¼": 0.8, "ì—¬ìˆ˜": 1.0, "ìˆœì²œ": 0.8, "ëª©í¬": 0.8,
        # ì¶©ì²­ë„
        "ì¶©ì£¼": 0.8, "ì²œì•ˆ": 0.9, "ì²­ì£¼": 0.8, "ê³µì£¼": 0.8,
        # ê¸°íƒ€
        "í†µì˜": 0.9, "ê±°ì œ": 0.9
    }
    
    # ê¸°ë³¸ ì¼ì¼ ë¹„ìš© (1ì¸ ê¸°ì¤€) - êµ­ë‚´ ì—¬í–‰ í˜„ì‹¤ì  ë¹„ìš©
    base_daily_cost = {
        "ìˆ™ë°•": 35000,    # í‰ê·  ìˆ™ë°•ë¹„ (ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤/ëª¨í…” ê¸°ì¤€)
        "ì‹ì‚¬": 25000,    # 3ë¼ ì‹ì‚¬ë¹„ (ì•„ì¹¨ 4ì²œ, ì ì‹¬ 10ì²œ, ì €ë… 11ì²œ)
        "êµí†µ": 10000,    # ì§€ì—­ ë‚´ êµí†µë¹„ (ë²„ìŠ¤/ì§€í•˜ì² /íƒì‹œ)
        "ê´€ê´‘": 15000,    # ì…ì¥ë£Œ, ì²´í—˜ë¹„ ë“±
        "ê¸°íƒ€": 8000      # ì‡¼í•‘, ê°„ì‹ ë“±
    }
    
    # ì´ ê¸°ë³¸ ì¼ì¼ ë¹„ìš©
    total_daily_cost = sum(base_daily_cost.values())  # 93,000ì›
    
    # ì˜ˆì‚° ë“±ê¸‰ë³„ ë¹„ìš© ì¡°ì •
    budget_adjusted_cost = total_daily_cost * budget_multipliers.get(budget, 1.0)
    
    # ì§€ì—­ë³„ ë¹„ìš© ì¡°ì •
    region_multiplier = 1.0
    destination_lower = destination.lower()
    for region, multiplier in region_multipliers.items():
        if region in destination_lower:
            region_multiplier = multiplier
            break
    
    # ìµœì¢… ì¼ì¼ ë¹„ìš©
    final_daily_cost = budget_adjusted_cost * region_multiplier
    
    # ì—¬í–‰ ì¼ìˆ˜ì— ë”°ë¥¸ í• ì¸ (ì¥ê¸° ì—¬í–‰ ì‹œ ì¼ë¶€ ë¹„ìš© ì ˆì•½)
    if travel_days >= 7:
        day_discount = 0.85  # 15% í• ì¸ (ì¥ê¸° ì—¬í–‰)
    elif travel_days >= 5:
        day_discount = 0.9   # 10% í• ì¸ (ì¤‘ì¥ê¸° ì—¬í–‰)
    elif travel_days >= 3:
        day_discount = 0.95  # 5% í• ì¸ (ë‹¨ê¸° ì—¬í–‰)
    else:
        day_discount = 1.0   # í• ì¸ ì—†ìŒ (1-2ì¼)
    
    # ìµœì¢… 1ì¸ë‹¹ ì´ ë¹„ìš© ê³„ì‚°
    total_cost = final_daily_cost * travel_days * day_discount
    
    # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸
    print(f"=== ë¹„ìš© ê³„ì‚° ìƒì„¸ ===")
    print(f"ì¼ì¼ ê¸°ë³¸ë¹„ìš©: {total_daily_cost:,}ì›")
    print(f"ì˜ˆì‚° ë“±ê¸‰ ({budget}): {budget_multipliers.get(budget, 1.0)}ë°°")
    print(f"ì˜ˆì‚° ì¡°ì •í›„: {budget_adjusted_cost:,}ì›")
    print(f"ì§€ì—­ ({destination}): {region_multiplier}ë°°")
    print(f"ì§€ì—­ ì¡°ì •í›„: {final_daily_cost:,}ì›")
    print(f"ì—¬í–‰ ì¼ìˆ˜: {travel_days}ì¼")
    print(f"ì¼ìˆ˜ í• ì¸: {day_discount}ë°°")
    print(f"ìµœì¢… ì´ë¹„ìš©: {total_cost:,}ì›")
    print(f"1ì¸ë‹¹ ì¼í‰ê· : {total_cost/travel_days:,.0f}ì›")
    
    return int(total_cost)





# ========================================
# í˜¸í…” ê²€ìƒ‰ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
# ========================================
# ì´ í´ë˜ìŠ¤ëŠ” í˜¸í…” ì •ë³´ë¥¼ ì œê³µí•˜ê³  ì˜ˆì•½ ë§í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤

class HotelSearchService:
    """í˜¸í…” ê²€ìƒ‰ ë° ì˜ˆì•½ ë§í¬ ìƒì„± ì„œë¹„ìŠ¤"""
    
    @staticmethod
    def create_booking_links(destination: str, check_in: str, check_out: str, guests: int, rooms: int, hotel_name: str = "") -> dict:
        """ê° í˜¸í…” ì˜ˆì•½ ì‚¬ì´íŠ¸ì˜ ê²€ìƒ‰ ë§í¬ë¥¼ ìƒì„±í•˜ëŠ” ë©”ì„œë“œ"""
        
        # ë‚ ì§œ í˜•ì‹ì„ ë³€í™˜í•©ë‹ˆë‹¤ (YYYY-MM-DD -> DD/MM/YYYY)
        # ì¼ë¶€ ì˜ˆì•½ ì‚¬ì´íŠ¸ëŠ” ë‹¤ë¥¸ ë‚ ì§œ í˜•ì‹ì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤
        try:
            check_in_date = datetime.strptime(check_in, "%Y-%m-%d")
            check_out_date = datetime.strptime(check_out, "%Y-%m-%d")
            check_in_formatted = check_in_date.strftime("%d/%m/%Y")
            check_out_formatted = check_out_date.strftime("%d/%m/%Y")
        except:
            # ë‚ ì§œ ë³€í™˜ì— ì‹¤íŒ¨í•˜ë©´ ì›ë³¸ í˜•ì‹ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤
            check_in_formatted = check_in
            check_out_formatted = check_out
        
        # URL ì¸ì½”ë”©: í•œê¸€ì´ë‚˜ íŠ¹ìˆ˜ë¬¸ìë¥¼ URLì— ì•ˆì „í•˜ê²Œ í¬í•¨ì‹œí‚¤ê¸° ìœ„í•œ ì²˜ë¦¬
        encoded_destination = urllib.parse.quote(destination)
        encoded_hotel_name = urllib.parse.quote(hotel_name) if hotel_name else ""
        
        # ê° ì˜ˆì•½ ì‚¬ì´íŠ¸ë³„ ê²€ìƒ‰ ë§í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤
        links = {
            "hotels": {
                "name": "í˜¸í…”ìŠ¤ë‹·ì»´",
                "url": f"https://kr.hotels.com/Hotel-Search?destination={encoded_destination}&flexibility=0_DAY&d1={check_in}&startDate={check_in}&d2={check_out}&endDate={check_out}&adults={guests}&rooms={rooms}",
                "icon": "ğŸ¨"
            },
            "airbnb": {
                "name": "ì—ì–´ë¹„ì•¤ë¹„",
                "url": f"https://www.airbnb.co.kr/s/{encoded_destination}/homes?checkin={check_in}&checkout={check_out}&adults={guests}&children=0&infants=0&pets=0",
                "icon": "ğŸ "
            },
            "agoda": {
                "name": "ì•„ê³ ë‹¤",
                "url": f"https://www.agoda.com/ko-kr/search?textToSearch={encoded_destination}&checkIn={check_in}&checkOut={check_out}&rooms={rooms}&adults={guests}&children=0&locale=ko-kr&currency=KRW&travellerType=1",
                "icon": "ğŸ›ï¸"
            },
            "booking": {
                "name": "ë¶€í‚¹ë‹·ì»´",
                "url": f"https://www.booking.com/searchresults.html?ss={encoded_destination}&checkin={check_in}&checkout={check_out}&group_adults={guests}&no_rooms={rooms}",
                "icon": "ğŸ“…"
            }
        }
        
        # íŠ¹ì • í˜¸í…”ëª…ì´ ìˆëŠ” ê²½ìš° ë” êµ¬ì²´ì ì¸ ê²€ìƒ‰ ë§í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤
        if hotel_name:
            links["hotels"]["url"] = f"https://kr.hotels.com/Hotel-Search?destination={encoded_destination}&flexibility=0_DAY&d1={check_in}&startDate={check_in}&d2={check_out}&endDate={check_out}&adults={guests}&rooms={rooms}&q={encoded_hotel_name}"
            links["agoda"]["url"] = f"https://www.agoda.com/ko-kr/search?textToSearch={encoded_destination}&hotelName={encoded_hotel_name}&checkIn={check_in}&checkOut={check_out}&rooms={rooms}&adults={guests}&children=0&locale=ko-kr&currency=KRW&travellerType=1"
            links["booking"]["url"] = f"https://www.booking.com/searchresults.html?ss={encoded_destination}&hotelName={encoded_hotel_name}&checkin={check_in}&checkout={check_out}&group_adults={guests}&no_rooms={rooms}"
        
        return links
    
    @staticmethod
    def create_trip_hotel_search_links(destination: str, check_in: str, check_out: str, guests: int, rooms: int) -> dict:
        """ì „ì²´ ì—¬í–‰ì— ëŒ€í•œ í˜¸í…” ê²€ìƒ‰ ë§í¬ë¥¼ ìƒì„±í•˜ëŠ” ë©”ì„œë“œ"""
        # ì£¼ìš” í˜¸í…” ì˜ˆì•½ ì‚¬ì´íŠ¸ë“¤ì˜ ê²€ìƒ‰ ë§í¬ ìƒì„±
        search_links = {
            "hotels": {
                "name": "í˜¸í…”ìŠ¤ë‹·ì»´",
                "url": f"https://kr.hotels.com/Hotel-Search?destination={urllib.parse.quote(destination)}&flexibility=0_DAY&d1={check_in}&startDate={check_in}&d2={check_out}&endDate={check_out}&adults={guests}&rooms={rooms}",
                "icon": "ğŸ¨",
                "description": "í˜¸í…”ìŠ¤ë‹·ì»´ì—ì„œ í˜¸í…” ê²€ìƒ‰í•˜ê¸°"
            },
            "yeogi": {
                "name": "ì—¬ê¸°ì–´ë•Œ",
                "url": f"https://www.yeogi.com/domestic-accommodations?keyword={urllib.parse.quote(destination)}&checkIn={check_in}&checkOut={check_out}&personal={guests}&freeForm=false",
                "icon": "ğŸ¨",
                "description": "ì—¬ê¸°ì–´ë•Œì—ì„œ í˜¸í…” ê²€ìƒ‰í•˜ê¸°"
            },
            "booking": {
                "name": "ë¶€í‚¹ë‹·ì»´",
                "url": f"https://www.booking.com/searchresults.html?ss={urllib.parse.quote(destination)}&checkin={check_in}&checkout={check_out}&group_adults={guests}&no_rooms={rooms}",
                "icon": "ğŸ“…",
                "description": "ë¶€í‚¹ë‹·ì»´ì—ì„œ í˜¸í…” ê²€ìƒ‰í•˜ê¸°"
            },
            "airbnb": {
                "name": "ì—ì–´ë¹„ì•¤ë¹„",
                "url": f"https://www.airbnb.co.kr/s/{urllib.parse.quote(destination)}/homes?checkin={check_in}&checkout={check_out}&adults={guests}&children=0&infants=0&pets=0",
                "icon": "ğŸ ",
                "description": "ì—ì–´ë¹„ì•¤ë¹„ì—ì„œ ìˆ™ì†Œ ê²€ìƒ‰í•˜ê¸°"
            }
        }
        
        return {
            "destination": destination,
            "check_in": check_in,
            "check_out": check_out,
            "guests": guests,
            "rooms": rooms,
            "search_links": search_links
        }
    
    @staticmethod
    def _extract_location_from_activity(activity_text: str, destination: str) -> str:
        """í™œë™ í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” ì¥ì†Œëª…ì„ ì¶”ì¶œí•˜ëŠ” ë©”ì„œë“œ"""
        if not activity_text:
            return destination
        
        # êµ¬ì²´ì ì¸ ê´€ê´‘ì§€ í‚¤ì›Œë“œ íŒ¨í„´ (2ê¸€ì ì´ìƒ ê³ ìœ ëª…ì‚¬ + ì ‘ë¯¸ì‚¬)
        location_patterns = [
            # ìì—° ê´€ê´‘ì§€
            r'([ê°€-í£]{2,}í•´ìˆ˜ìš•ì¥)',  # í•´ìš´ëŒ€í•´ìˆ˜ìš•ì¥, ê²½í¬í•´ìˆ˜ìš•ì¥
            r'([ê°€-í£]{2,}í•´ë³€)',      # ê´‘ì•ˆë¦¬í•´ë³€, ê²½í¬í•´ë³€
            r'([ê°€-í£]{2,}í­í¬)',      # ì²œì§€ì—°í­í¬, ì •ë°©í­í¬
            r'([ê°€-í£]{2,}ì‚°)',        # í•œë¼ì‚°, ì§€ë¦¬ì‚°
            r'([ê°€-í£]{2,}ë´‰)',        # ì„±ì‚°ì¼ì¶œë´‰, ìš°ë„ë´‰
            r'([ê°€-í£]{2,}ê°•)',        # í•œê°•, ë‚™ë™ê°•
            r'([ê°€-í£]{2,}í˜¸ìˆ˜)',      # ì²œì§€í˜¸ìˆ˜, ë°¤ì„¬í˜¸ìˆ˜
            r'([ê°€-í£]{2,}êµ´)',        # ë§Œì¥êµ´, í˜‘ì¬êµ´
            
            # ë¬¸í™”/ì—­ì‚¬ ê´€ê´‘ì§€
            r'([ê°€-í£]{2,}ì‚¬)',        # ë¶ˆêµ­ì‚¬, í•´ì¸ì‚¬, ì¡°ê³„ì‚¬
            r'([ê°€-í£]{2,}ê¶)',        # ê²½ë³µê¶, ì°½ë•ê¶, ë•ìˆ˜ê¶
            r'([ê°€-í£]{2,}ì„±)',        # ìˆ˜ì›í™”ì„±, ë‚¨í•œì‚°ì„±
            r'([ê°€-í£]{2,}íƒ‘)',        # ë‚¨ì‚°íƒ€ì›Œ, ë¶€ì‚°íƒ€ì›Œ
            r'([ê°€-í£]{2,}ë°•ë¬¼ê´€)',    # êµ­ë¦½ì¤‘ì•™ë°•ë¬¼ê´€, ì „ìŸê¸°ë…ê´€
            r'([ê°€-í£]{2,}ë¯¸ìˆ ê´€)',    # êµ­ë¦½í˜„ëŒ€ë¯¸ìˆ ê´€, ë¦¬ì›€ë¯¸ìˆ ê´€
            r'([ê°€-í£]{2,}ë¬¸í™”ì¬)',    # ì„êµ´ì•”ë¬¸í™”ì¬
            
            # ë„ì‹œ ì¸í”„ë¼
            r'([ê°€-í£]{2,}ì‹œì¥)',      # ë™ëŒ€ë¬¸ì‹œì¥, ë‚¨ëŒ€ë¬¸ì‹œì¥, ìê°ˆì¹˜ì‹œì¥
            r'([ê°€-í£]{2,}ê³µì›)',      # ë‚¨ì‚°ê³µì›, ì˜¬ë¦¼í”½ê³µì›, í•œê°•ê³µì›
            r'([ê°€-í£]{2,}ì—­)',        # ì„œìš¸ì—­, ë¶€ì‚°ì—­, ì œì£¼ê³µí•­
            r'([ê°€-í£]{2,}í•­)',        # ë¶€ì‚°í•­, ì¸ì²œí•­, ì œì£¼í•­
            r'([ê°€-í£]{2,}ë‹¤ë¦¬)',      # ê´‘ì•ˆëŒ€êµ, í•œê°•ëŒ€êµ, ë°˜í¬ëŒ€êµ
            r'([ê°€-í£]{2,}ê±°ë¦¬)',      # ëª…ë™ê±°ë¦¬, í™ëŒ€ê±°ë¦¬, ê°€ë¡œìˆ˜ê¸¸
            r'([ê°€-í£]{2,}ë¡œ)',        # ì²­ê³„ì²œë¡œ, ê°•ë‚¨ëŒ€ë¡œ
            
            # í–‰ì •êµ¬ì—­ (êµ¬ì²´ì ì¸ ì§€ëª…)
            r'([ê°€-í£]{2,}ë™)',        # ëª…ë™, í™ëŒ€ë™, ê°•ë‚¨ë™
            r'([ê°€-í£]{2,}êµ¬)',        # ê°•ë‚¨êµ¬, ì¢…ë¡œêµ¬, í•´ìš´ëŒ€êµ¬
            r'([ê°€-í£]{2,}ì‹œ)',        # ë¶€ì‚°ì‹œ, ì œì£¼ì‹œ, ê°•ë¦‰ì‹œ
            r'([ê°€-í£]{2,}êµ°)',        # ì œì£¼ì„œê·€í¬ì‹œ, ê°•í™”êµ°
            r'([ê°€-í£]{2,}ì)',        # ì„±ì‚°ì, í•œë¦¼ì
            r'([ê°€-í£]{2,}ë©´)',        # ì• ì›”ë©´, êµ¬ì¢Œë©´
            
            # ë³µí•© ëª…ì¹­
            r'([ê°€-í£]{2,}í…Œë§ˆíŒŒí¬)',  # ì—ë²„ëœë“œí…Œë§ˆíŒŒí¬, ë¡¯ë°ì›”ë“œí…Œë§ˆíŒŒí¬
            r'([ê°€-í£]{2,}ë¦¬ì¡°íŠ¸)',    # ì œì£¼ì‹ í™”ì›”ë“œë¦¬ì¡°íŠ¸
            r'([ê°€-í£]{2,}ì•„ì¿ ì•„ë¦¬ì›€)', # ì½”ì—‘ìŠ¤ì•„ì¿ ì•„ë¦¬ì›€
            r'([ê°€-í£]{2,}ì „ë§ëŒ€)',    # ì„œìš¸ìŠ¤ì¹´ì´ì „ë§ëŒ€, ë¶€ì‚°íƒ€ì›Œì „ë§ëŒ€
        ]
        
        for pattern in location_patterns:
            match = re.search(pattern, activity_text)
            if match:
                return match.group(1)
        
        # íŠ¹ì • í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì „ì²´ í™œë™ í…ìŠ¤íŠ¸ì—ì„œ ì²« ë²ˆì§¸ ëª…ì‚¬ ì¶”ì¶œ
        words = activity_text.split()
        for word in words:
            if len(word) >= 2 and re.match(r'^[ê°€-í£]+$', word):
                return word
        
        # ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ëª©ì ì§€ ë°˜í™˜
        return destination

# ========================================
# API ì—”ë“œí¬ì¸íŠ¸ ì •ì˜
# ========================================
# ì—”ë“œí¬ì¸íŠ¸ëŠ” ì›¹ ì„œë²„ì—ì„œ íŠ¹ì • ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ì£¼ì†Œì…ë‹ˆë‹¤

@app.get("/")
async def root():
    """ë£¨íŠ¸ ê²½ë¡œ (ë©”ì¸ í˜ì´ì§€) - ì„œë²„ê°€ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ìš©ë„"""
    return {"message": "ì—¬í–‰ í”Œë˜ë„ˆ AI API"}

# ========================================
# ì§„í–‰ ìƒí™© SSE ì—”ë“œí¬ì¸íŠ¸
# ========================================

async def generate_progress_events(request_data: dict):
    """ì—¬í–‰ ê³„íš ìƒì„± ê³¼ì •ì˜ ì§„í–‰ ìƒí™©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì „ë‹¬í•˜ëŠ” ì œë„ˆë ˆì´í„°"""
    try:
        # 1ë‹¨ê³„: ìš”ì²­ ê²€ì¦
        yield f"data: {json.dumps({'step': 1, 'message': 'ì—¬í–‰ ì •ë³´ë¥¼ ê²€ì¦í•˜ê³  ìˆìŠµë‹ˆë‹¤...', 'progress': 8, 'total_steps': 11}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.8)
        
        # 2ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬
        yield f"data: {json.dumps({'step': 2, 'message': 'ì—¬í–‰ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...', 'progress': 15, 'total_steps': 11}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(1.0)
        
        # 3ë‹¨ê³„: AI ì‹œìŠ¤í…œ ì¤€ë¹„
        yield f"data: {json.dumps({'step': 3, 'message': 'AI ì‹œìŠ¤í…œì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤...', 'progress': 25, 'total_steps': 11}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(1.2)
        
        # 4ë‹¨ê³„: ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
        yield f"data: {json.dumps({'step': 4, 'message': 'ëª©ì ì§€ ê¸°ë³¸ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ìˆìŠµë‹ˆë‹¤...', 'progress': 35, 'total_steps': 11}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(1.4)
        
        # 5ë‹¨ê³„: ê´€ê´‘ì§€ ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ
        yield f"data: {json.dumps({'step': 5, 'message': 'ê´€ê´‘ì§€ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì¡°íšŒí•˜ê³  ìˆìŠµë‹ˆë‹¤...', 'progress': 45, 'total_steps': 11}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(1.6)
        
        # 6ë‹¨ê³„: ë§ì¶¤í˜• ì¶”ì²œ ì¤€ë¹„
        yield f"data: {json.dumps({'step': 6, 'message': 'ë§ì¶¤í˜• ì¶”ì²œì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤...', 'progress': 55, 'total_steps': 11}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(1.2)
        
        # 7ë‹¨ê³„: ì—¬í–‰ íŒ¨í„´ ë¶„ì„
        yield f"data: {json.dumps({'step': 7, 'message': 'ì—¬í–‰ íŒ¨í„´ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...', 'progress': 65, 'total_steps': 11}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(1.4)
        
        # 8ë‹¨ê³„: ì¼ì • ìµœì í™” ì¤€ë¹„
        yield f"data: {json.dumps({'step': 8, 'message': 'ì¼ì • ìµœì í™”ë¥¼ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤...', 'progress': 75, 'total_steps': 11}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(1.0)
        
        # 9ë‹¨ê³„: AI ëª¨ë¸ ë¡œë”©
        yield f"data: {json.dumps({'step': 9, 'message': 'AI ëª¨ë¸ì„ ë¡œë”©í•˜ê³  ìˆìŠµë‹ˆë‹¤...', 'progress': 82, 'total_steps': 11}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.8)
        
        # 10ë‹¨ê³„: ìµœì¢… ì¤€ë¹„ ë‹¨ê³„
        yield f"data: {json.dumps({'step': 10, 'message': 'ì—¬í–‰ ê³„íš ìƒì„±ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤...', 'progress': 88, 'total_steps': 11}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.8)
        
        # 11ë‹¨ê³„: API í˜¸ì¶œ ì§ì „
        yield f"data: {json.dumps({'step': 11, 'message': 'AIê°€ ì—¬í–‰ ê³„íšì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...', 'progress': 90, 'total_steps': 11}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.8)
        
        # ì‹¤ì œ OpenAI API í˜¸ì¶œì€ plan-trip APIì—ì„œ ì²˜ë¦¬ë¨ - ì—¬ê¸°ì„œëŠ” 90%ê¹Œì§€ë§Œ
        
    except Exception as e:
        yield f"data: {json.dumps({'error': str(e)}, ensure_ascii=False)}\n\n"

@app.get("/plan-trip-progress")
async def plan_trip_progress(
    destination: str,
    start_date: str,
    end_date: str,
    budget: str = "ë³´í†µ",
    guests: int = 2,
    rooms: int = 1
):
    """ì—¬í–‰ ê³„íš ìƒì„± ì§„í–‰ ìƒí™©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì „ë‹¬í•˜ëŠ” SSE ì—”ë“œí¬ì¸íŠ¸"""
    request_data = {
        'destination': destination,
        'start_date': start_date,
        'end_date': end_date,
        'budget': budget,
        'guests': guests,
        'rooms': rooms
    }
    
    return StreamingResponse(
        generate_progress_events(request_data),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "GET, POST, PUT, DELETE, OPTIONS",
            "Access-Control-Allow-Headers": "*",
        }
    )

@app.post("/plan-trip", response_model=TripPlan)
async def plan_trip(request: TripRequest):
    """ì—¬í–‰ ê³„íšì„ ìƒì„±í•˜ëŠ” ë©”ì¸ API"""
    try:
        # ì…ë ¥ ë°ì´í„° ê²€ì¦
        if not request.destination or request.destination.strip() == "":
            raise HTTPException(status_code=400, detail="ëª©ì ì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        if not request.start_date or request.start_date.strip() == "":
            raise HTTPException(status_code=400, detail="ì—¬í–‰ ì‹œì‘ì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        
        if not request.end_date or request.end_date.strip() == "":
            raise HTTPException(status_code=400, detail="ì—¬í–‰ ì¢…ë£Œì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        
        # ë‚ ì§œ í˜•ì‹ ê²€ì¦ ë° íŒŒì‹±
        try:
            start_date = datetime.strptime(request.start_date, "%Y-%m-%d")
            end_date = datetime.strptime(request.end_date, "%Y-%m-%d")
        except ValueError:
            raise HTTPException(status_code=400, detail="ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        # ë‚ ì§œ ë…¼ë¦¬ ê²€ì¦
        if start_date >= end_date:
            raise HTTPException(status_code=400, detail="ì—¬í–‰ ì‹œì‘ì¼ì€ ì¢…ë£Œì¼ë³´ë‹¤ ì´ì „ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
        
        # ì—¬í–‰ ê¸°ê°„ ê²€ì¦ (ìµœëŒ€ 4ë°• 5ì¼)
        travel_days = (end_date - start_date).days + 1
        if travel_days > 5:
            raise HTTPException(status_code=400, detail="ì—¬í–‰ ê¸°ê°„ì€ ìµœëŒ€ 4ë°• 5ì¼ê¹Œì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        if travel_days < 1:
            raise HTTPException(status_code=400, detail="ì—¬í–‰ ê¸°ê°„ì€ ìµœì†Œ 1ì¼ ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
        
        # ê³¼ê±° ë‚ ì§œ ê²€ì¦
        current_date = datetime.now().date()
        if start_date.date() < current_date:
            raise HTTPException(status_code=400, detail="ì—¬í–‰ ì‹œì‘ì¼ì€ ì˜¤ëŠ˜ ì´í›„ ë‚ ì§œì—¬ì•¼ í•©ë‹ˆë‹¤.")
        
        # ë¡œê·¸ì— ìš”ì²­ ì •ë³´ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤
        logger.info(f"ì—¬í–‰ ê³„íš ìƒì„± ìš”ì²­: {request.destination}, {request.start_date} ~ {request.end_date} ({travel_days}ì¼)")
        
        # í˜¸í…” ê²€ìƒ‰ ì„œë¹„ìŠ¤ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤
        hotel_service = HotelSearchService()
        
        # ì¹´ì¹´ì˜¤ ë¡œì»¬ ì„œë¹„ìŠ¤ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤
        kakao_service = KakaoLocalService()
        
        # OpenAI APIì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸(ì§ˆë¬¸)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤
        # í”„ë¡¬í”„íŠ¸ëŠ” AIì—ê²Œ ë¬´ì—‡ì„ í•´ë‹¬ë¼ê³  ìš”ì²­í•˜ëŠ” ë©”ì‹œì§€ì…ë‹ˆë‹¤
        prompt = f"""
Destination: {request.destination}
Travel period: {request.start_date} ~ {request.end_date} (total {travel_days} days)
People: {request.guests}
Rooms: {request.rooms}
Budget: {request.budget}
Interests: {', '.join(request.interests) if request.interests else 'general tourism'}
Travel pace: {request.travelPace if request.travelPace else 'normal'}

Create a travel itinerary matching these conditions.

ğŸš¨ **TOP RULE: NO DUPLICATE PLACES**

**âš ï¸ IMPORTANT: Follow these steps before writing:**

1ï¸âƒ£ **Write Day 1 activities** â†’ Remember used places
2ï¸âƒ£ **Before writing Day 2** â†’ Check no overlap with Day 1 places
3ï¸âƒ£ **Before writing Day 3** â†’ Check no overlap with Day 1 & 2 places
4ï¸âƒ£ **Continue avoiding all previous days' places**

**Duplicate prevention examples:**
âŒ Day 1: "Haeundae Beach walk" â†’ Day 2: "Sunrise at Haeundae Beach" (same place!)
âŒ Day 1: "N Seoul Tower" â†’ Day 3: "Namsan Tower" (same place, different name!)
âŒ Day 1: "Jagalchi Market" â†’ Day 2: "Jagalchi Fish Center" (same building!)

âœ… Day 1: "Haeundae Beach" â†’ Day 2: "Gwangalli Beach" (completely different beach)
âœ… Day 1: "Gyeongbokgung Palace" â†’ Day 2: "Changdeokgung Palace" (different palace)

**Activities per travel pace:**
- "Relaxed": 3 activities per day (leisurely pace)
- "Tight": 4 activities per day (packed schedule)

**Other rules:**
- No vague names: "Busan beach" â†’ "Haeundae Beach", "beach" â†’ "Beach"
- Exclude hotel info
- Recommend only famous places that definitely exist

**âš ï¸ Writing checklist:**
â–¡ Has this place appeared in previous days?
â–¡ Is there a similar-named place already?
â–¡ Is it a different facility in same building/area?
â†’ If any applies, change to completely different place!

**ğŸ”‘ IMPORTANT: location vs title fields**
- **location**: actual place name only (e.g., "Haeundae Beach", "Jagalchi Market", "Gyeongbokgung Palace")
- **Beach related**: use "Beach" instead of "beach" (e.g., "Hajodae beach" â†’ "Hajodae Beach")
- **title**: display activity name (e.g., "Haeundae walk", "Jagalchi market tour", "Gyeongbokgung visit")

**ğŸ“ Travel tips writing guide:**
- **Specific and practical info**: "Check weather" âŒ â†’ "Gangneung has big temperature difference, bring outerwear" âœ…
- **Reflect regional characteristics**: Include actual local features and precautions
- **Actually helpful tips**: Useful info tourists really need to know
- **Specific time/place/method**: "Go a bit early" âŒ â†’ "Haeundae Beach is quiet before 9 AM" âœ…
- **Local info**: Transportation, food, culture, reservations etc.
- **Consider season/weather**: Reflect weather and seasonal characteristics
- **Cost related**: Actual costs or money-saving methods

Respond in JSON format:
{{
    "destination": "{request.destination}",
    "duration": "{travel_days}ì¼",
    "itinerary": [
        {{
            "day": 1,
            "date": "{request.start_date}",
            "activities": [
                {{
                    "time": "09:00",
                    "title": "activity name (e.g., Haeundae walk)",
                    "location": "actual place name only (e.g., Haeundae Beach, Hajodae Beach)",
                    "description": "activity description",
                    "duration": "duration"
                }}
            ]
        }}
    ],
    "total_cost": "1ì¸ë‹¹ XXX,XXXì›",
    "tips": [
        "Specific practical travel tip (e.g., 'Gangneung has big temperature difference, bring outerwear')",
        "Regional characteristics and precautions (e.g., 'Haeundae Beach is quiet before 9 AM')", 
        "Local transportation/food/culture info (e.g., 'Jagalchi Market is most lively after 2 PM')"
    ]
}}
        """
        
        logger.info("=== OpenAI API í˜¸ì¶œ ì‹œì‘ ===")
        logger.info(f"ëª©ì ì§€: {request.destination}, ì—¬í–‰ê¸°ê°„: {travel_days}ì¼")
        logger.info(f"ëª¨ë¸: gpt-4o, ìµœëŒ€í† í°: 3000, Temperature: 0.3")
        
        # ì‹¤ì œ OpenAI API í˜¸ì¶œ ì‹œì‘ ì‹œì  ê¸°ë¡
        api_start_time = datetime.now()
        logger.info(f"API í˜¸ì¶œ ì‹œì‘ ì‹œê°„: {api_start_time.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]}")
        
        # OpenAI APIë¥¼ í˜¸ì¶œí•˜ì—¬ AI ì—¬í–‰ ê³„íšì„ ìƒì„±í•©ë‹ˆë‹¤
        # ìµœì‹  OpenAI API ì‚¬ìš©ë²•ì„ ì ìš©í–ˆìŠµë‹ˆë‹¤
        response = client.chat.completions.create(
            model="gpt-4o",  # ì‚¬ìš©í•  AI ëª¨ë¸
            messages=[
                {"role": "system", "content": f"""You are a professional travel planner. Create a {travel_days}-day travel plan.

ğŸš¨ **TOP RULE: NO DUPLICATE PLACES**

**Required writing process:**
1. Complete all Day 1 activities
2. When writing Day 2: Check Day 1 places in mind, choose only completely different places
3. When writing Day 3: Check all Day 1+2 places, choose only completely different places
4. Write each day avoiding all previous days' places

**Duplicate check methods:**
- Same place name = duplicate (Haeundae Beach = Haeundae Beach)
- Same place with different name = duplicate (N Seoul Tower = Namsan Tower)
- Different facilities in same building/area = duplicate (Jagalchi Market = Jagalchi Fish Center)

**Never do:**
âŒ "Day 1: Haeundae Beach â†’ Day 2: Haeundae Beach" 
âŒ Repeat same place with different names

**Must do:**
âœ… Each place appears only once in entire trip
âœ… Use specific proper nouns
âœ… Match travel pace activity count: Relaxed(3), Tight(4)
âœ… Respond accurately in JSON format"""},
                {"role": "user", "content": prompt}
            ],
            max_tokens=3000,  # AI ì‘ë‹µì˜ ìµœëŒ€ ê¸¸ì´ (ë” ê¸´ ì‘ë‹µì„ ìœ„í•´ ì¦ê°€)
            temperature=0.3   # AIì˜ ì°½ì˜ì„± ìˆ˜ì¤€ì„ ë‚®ì¶° ë” ì¼ê´€ë˜ê³  ê·œì¹™ì„ ì˜ ë”°ë¥´ë„ë¡ ì„¤ì •
        )
        
        # API í˜¸ì¶œ ì™„ë£Œ ì‹œì  ê¸°ë¡
        api_end_time = datetime.now()
        api_duration = (api_end_time - api_start_time).total_seconds()
        logger.info(f"=== OpenAI API ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ ===")
        logger.info(f"API í˜¸ì¶œ ì™„ë£Œ ì‹œê°„: {api_end_time.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]}")
        logger.info(f"API ì‘ë‹µ ì†Œìš” ì‹œê°„: {api_duration:.2f}ì´ˆ")
        
        # AI ì‘ë‹µì„ íŒŒì‹±(ë¶„ì„)í•©ë‹ˆë‹¤
        content = response.choices[0].message.content
        logger.info(f"AI ì‘ë‹µ ë‚´ìš©: {content[:200]}...")
        
        # JSON ì‘ë‹µì„ ì¶”ì¶œí•˜ë ¤ê³  ì‹œë„í•©ë‹ˆë‹¤
        try:
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (AIê°€ ë•Œë¡œëŠ” ì„¤ëª…ê³¼ í•¨ê»˜ JSONì„ ë°˜í™˜í•˜ê¸° ë•Œë¬¸)
            start_idx = content.find('{')
            end_idx = content.rfind('}') + 1
            if start_idx != -1 and end_idx != -1:
                json_str = content[start_idx:end_idx]
                logger.info(f"ì¶”ì¶œëœ JSON: {json_str}")
                trip_data = json.loads(json_str)
                
                # ì¤‘ë³µ ì¥ì†Œ ì œê±°
                logger.info("ì¤‘ë³µ ì¥ì†Œ ê²€ì‚¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
                trip_data = await remove_duplicate_locations(trip_data, request.destination)
                
                # ì¤‘ë³µ ì œê±° í›„ ìµœì¢… ê²€ì¦
                logger.info("ì¤‘ë³µ ì œê±° í›„ ìµœì¢… ê²€ì¦ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
                final_duplicates = await check_final_duplicates(trip_data)
                if final_duplicates:
                    logger.warning(f"ìµœì¢… ê²€ì¦ì—ì„œ ì—¬ì „íˆ ì¤‘ë³µ ë°œê²¬: {final_duplicates}")
                    # ì¶”ê°€ ì¤‘ë³µ ì œê±° ì‹œë„
                    trip_data = await remove_duplicate_locations(trip_data, request.destination)
                
                # ì¹´ì¹´ì˜¤ APIë¡œ ì¥ì†Œ ê²€ì¦ ë° ë³´ê°•
                logger.info("ì¹´ì¹´ì˜¤ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¥ì†Œ ê²€ì¦ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
                trip_data = await verify_and_enrich_trip_data(trip_data, kakao_service, request.destination)
                
                # ìˆ™ë°• ì •ë³´ëŠ” trip_hotel_search ë§í¬ë¡œë§Œ ì œê³µí•˜ë¯€ë¡œ accommodation ì²˜ë¦¬ ìƒëµ
                
                # ì „ì²´ ì—¬í–‰ì— ëŒ€í•œ í˜¸í…” ê²€ìƒ‰ ë§í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤
                trip_hotel_search = hotel_service.create_trip_hotel_search_links(
                    request.destination, 
                    request.start_date, 
                    request.end_date,
                    request.guests,
                    request.rooms
                )
                trip_data["trip_hotel_search"] = trip_hotel_search
                
                # ìœ„ì¹˜ ê²€ì¦ ìˆ˜í–‰ (ì„ íƒì ) - 1ì¼ì°¨ ì¼ì • ëˆ„ë½ ë¬¸ì œë¡œ ì„ì‹œ ë¹„í™œì„±í™”
                validation_enabled = os.getenv('ENABLE_LOCATION_VALIDATION', 'false').lower() == 'true'
                validation_enabled = False  # ì„ì‹œë¡œ ê°•ì œ ë¹„í™œì„±í™”
                if validation_enabled:
                    try:
                        validation_result = validate_trip_locations(
                            trip_data.get("itinerary", []), 
                            request.destination
                        )
                        
                        # ê²€ì¦ ê²°ê³¼ê°€ ì¢‹ì§€ ì•Šì€ ê²½ìš° ê²½ê³  ë¡œê·¸
                        if validation_result['invalid_places_count'] > 0:
                            logger.warning(f"ìœ„ì¹˜ ê²€ì¦ ê²°ê³¼: {validation_result['invalid_places_count']}ê°œì˜ ì¥ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                            logger.warning(f"ë¬¸ì œ ì¥ì†Œë“¤: {[p['location'] for p in validation_result['invalid_places']]}")
                        
                        # ê²€ì¦ ê²°ê³¼ë¥¼ ì‘ë‹µì— í¬í•¨ (ê°œë°œìš©)
                        trip_data["location_validation"] = validation_result
                        
                    except Exception as e:
                        logger.error(f"ê¸°ì¡´ ìœ„ì¹˜ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
                
                # ì§€ì˜¤ì½”ë”© ê²€ì¦ ë¹„í™œì„±í™” (ì¹´ì¹´ì˜¤ APIë§Œ ì‚¬ìš©)
                logger.info("ì§€ì˜¤ì½”ë”© ê²€ì¦ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¹´ì¹´ì˜¤ APIë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                
                # ì‹¤ì œ ì¥ì†Œ ì •ë³´ ì¶”ê°€ ë¹„í™œì„±í™” (ì¹´ì¹´ì˜¤ APIë§Œ ì‚¬ìš©)
                logger.info("ì‹¤ì œ ì¥ì†Œ ì •ë³´ ì¶”ê°€ê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¹´ì¹´ì˜¤ APIë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                
                # TripPlan ëª¨ë¸ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤
                return TripPlan(**trip_data)
            else:
                logger.warning("JSON ì‘ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                raise ValueError("JSON ì‘ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
        except json.JSONDecodeError as e:
            # JSON íŒŒì‹±ì— ì‹¤íŒ¨í•œ ê²½ìš° ê¸°ë³¸ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤
            logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            
            # ì‹¤ì œ í˜¸í…” ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤
            popular_hotels = hotel_service.get_popular_hotels(request.destination)
            
            # ì‹¤ì œ í˜¸í…” ì •ë³´ë¡œ ê¸°ë³¸ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤
            accommodation_list = []
            for hotel in popular_hotels[:2]:  # ìƒìœ„ 2ê°œ í˜¸í…”ë§Œ ì‚¬ìš©
                hotel_info = HotelInfo(
                    name=hotel["name"],
                    type=hotel["type"],
                    price_range=hotel["price_range"],
                    booking_links=hotel_service.create_booking_links(
                        request.destination,
                        request.start_date,
                        request.end_date,
                        request.guests,
                        request.rooms,
                        hotel["name"]
                    ),
                    description=hotel["description"],
                    rating=hotel["rating"],
                    amenities=hotel["amenities"]
                )
                accommodation_list.append(hotel_info)
            
            # ì—¬í–‰ ê¸°ê°„ì— ë§ëŠ” ì¼ì •ì„ ìƒì„±í•©ë‹ˆë‹¤ (ìƒˆë¡œìš´ activities êµ¬ì¡°)
            itinerary_list = []
            for day in range(1, travel_days + 1):
                current_date = start_date + timedelta(days=day - 1)
                
                # ì—¬í–‰ í˜ì´ìŠ¤ì— ë”°ë¥¸ í™œë™ ìˆ˜ ê²°ì •
                if request.travelPace == "íƒ€ì´íŠ¸í•˜ê²Œ":
                    # í•˜ë£¨ 4ê°œ í™œë™
                    activities = [
                        {"time": "09:00", "title": f"{day}ì¼ì°¨ ì˜¤ì „ ê´€ê´‘", "location": f"{request.destination} ì£¼ìš” ê´€ê´‘ì§€", "description": "ì£¼ìš” ê´€ê´‘ì§€ ë°©ë¬¸", "duration": "2ì‹œê°„"},
                        {"time": "12:00", "title": f"ì ì‹¬ ë° í˜„ì§€ ëª…ì†Œ", "location": f"{request.destination} ë§›ì§‘", "description": "í˜„ì§€ ìŒì‹ ì²´í—˜ í›„ ëª…ì†Œ íƒë°©", "duration": "2ì‹œê°„"},
                        {"time": "15:00", "title": f"ì˜¤í›„ ì²´í—˜ í™œë™", "location": f"{request.destination} ì²´í—˜ì¥ì†Œ", "description": "ì•¡í‹°ë¹„í‹° ì°¸ì—¬", "duration": "2.5ì‹œê°„"},
                        {"time": "18:30", "title": f"ì €ë… ì‹ì‚¬", "location": f"{request.destination} ìŒì‹ì ", "description": "ì €ë… ì‹ì‚¬ ë° íœ´ì‹", "duration": "1.5ì‹œê°„"}
                    ]
                elif request.travelPace == "ë„ë„í•˜ê²Œ":
                    # í•˜ë£¨ 3ê°œ í™œë™
                    activities = [
                        {"time": "10:00", "title": f"{day}ì¼ì°¨ ì—¬ìœ ë¡œìš´ ê´€ê´‘", "location": f"{request.destination} ëŒ€í‘œ ê´€ê´‘ì§€", "description": "ì²œì²œíˆ ë‘˜ëŸ¬ë³´ë©° ì—¬ìœ ìˆê²Œ ê´€ê´‘", "duration": "3ì‹œê°„"},
                        {"time": "15:00", "title": f"ì ì‹¬ ë° í˜„ì§€ ì²´í—˜", "location": f"{request.destination} ìœ ëª… ë§›ì§‘", "description": "í˜„ì§€ íŠ¹ìƒ‰ ìŒì‹ì„ ì—¬ìœ ë¡­ê²Œ ì¦ê¸°ê³  ë¬¸í™” ì²´í—˜", "duration": "2.5ì‹œê°„"},
                        {"time": "19:00", "title": f"ì €ë… ì‹ì‚¬ ë° ì‚°ì±…", "location": f"{request.destination} ì €ë… ë§›ì§‘", "description": "í˜„ì§€ ìŒì‹ì„ ì¦ê¸°ë©° ì—¬ìœ ë¡œìš´ ì €ë… ì‚°ì±…", "duration": "2ì‹œê°„"}
                    ]
                else:  # ë³´í†µ
                    # í•˜ë£¨ 3ê°œ í™œë™
                    activities = [
                        {"time": "09:30", "title": f"{day}ì¼ì°¨ ì˜¤ì „ ê´€ê´‘", "location": f"{request.destination} ì£¼ìš” ê´€ê´‘ì§€", "description": "ì£¼ìš” ê´€ê´‘ì§€ ë°©ë¬¸", "duration": "2.5ì‹œê°„"},
                        {"time": "13:30", "title": f"ì ì‹¬ ë° ì˜¤í›„ í™œë™", "location": f"{request.destination} ë§›ì§‘", "description": "í˜„ì§€ ìŒì‹ ì²´í—˜ í›„ ì˜¤í›„ í™œë™", "duration": "3ì‹œê°„"},
                        {"time": "18:00", "title": f"ì €ë… ì‹ì‚¬", "location": f"{request.destination} ìŒì‹ì ", "description": "ì €ë… ì‹ì‚¬ ë° íœ´ì‹", "duration": "1.5ì‹œê°„"}
                    ]
                
                itinerary_list.append({
                    "day": day,
                    "date": current_date.strftime("%Y-%m-%d"),
                    "activities": activities,
                    "accommodation": f"{request.destination} ì¶”ì²œ í˜¸í…”"
                })
            
            # ì „ì²´ ì—¬í–‰ì— ëŒ€í•œ í˜¸í…” ê²€ìƒ‰ ë§í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤
            trip_hotel_search = hotel_service.create_trip_hotel_search_links(
                request.destination, 
                request.start_date, 
                request.end_date,
                request.guests,
                request.rooms
            )
            
            # ëŒ€ì¤‘êµí†µ ì •ë³´ëŠ” ì œê±°ë¨
            
            # ì—¬í–‰ ê¸°ê°„ ê³„ì‚° (ì‹¤ì œ ì—¬í–‰ ì¼ìˆ˜)
            start_date = datetime.strptime(request.start_date, "%Y-%m-%d")
            end_date = datetime.strptime(request.end_date, "%Y-%m-%d")
            travel_days = (end_date - start_date).days + 1  # ì‹¤ì œ ì—¬í–‰ ì¼ìˆ˜ (2ë°•3ì¼ = 3ì¼)
            
            # 1ì¸ë‹¹ ì˜ˆìƒ ë¹„ìš© ê³„ì‚° (ì˜ˆì‚° ë“±ê¸‰ë³„ ì„¸ë¶€ ê³„ì‚°)
            estimated_cost_per_person = calculate_trip_cost(request.budget, travel_days, request.destination)
            
            return TripPlan(
                destination=request.destination,
                duration=f"{travel_days}ì¼",
                itinerary=itinerary_list,
                total_cost=f"1ì¸ë‹¹ {estimated_cost_per_person:,}ì›",
                tips=["ì—¬í–‰ ì „ ë‚ ì§œ í™•ì¸", "í•„ìˆ˜í’ˆ ì¤€ë¹„", "í˜„ì§€ êµí†µ ì •ë³´ íŒŒì•…"],
                trip_hotel_search=trip_hotel_search
            )
            
    except Exception as e:
        # ì—ëŸ¬ê°€ ë°œìƒí•œ ê²½ìš° ë¡œê·¸ì— ê¸°ë¡í•˜ê³  HTTP ì—ëŸ¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤
        logger.error(f"ì—¬í–‰ ê³„íš ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ì—¬í–‰ ê³„íš ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.get("/hotel-links")
async def get_hotel_links(
    destination: str,
    check_in: str,
    check_out: str,
    guests: int = 2,
    rooms: int = 1
):
    """íŠ¹ì • ì¡°ê±´ì— ë§ëŠ” í˜¸í…” ê²€ìƒ‰ ë§í¬ë¥¼ ìƒì„±í•˜ëŠ” API"""
    try:
        hotel_service = HotelSearchService()
        links = hotel_service.create_booking_links(destination, check_in, check_out, guests, rooms)
        return {
            "destination": destination,
            "check_in": check_in,
            "check_out": check_out,
            "guests": guests,
            "rooms": rooms,
            "booking_links": links
        }
    except Exception as e:
        logger.error(f"í˜¸í…” ë§í¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise HTTPException(status_code=500, detail=f"í˜¸í…” ë§í¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.get("/popular-hotels/{destination}")
async def get_popular_hotels(destination: str):
    """íŠ¹ì • ëª©ì ì§€ì˜ ì¸ê¸° í˜¸í…” ì •ë³´ë¥¼ ì¡°íšŒí•˜ëŠ” API"""
    try:
        hotel_service = HotelSearchService()
        hotels = hotel_service.get_popular_hotels(destination)
        return {
            "destination": destination,
            "hotels": hotels
        }
    except Exception as e:
        logger.error(f"ì¸ê¸° í˜¸í…” ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ì¸ê¸° í˜¸í…” ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")



@app.get("/hotel-search")
async def search_hotels(
    destination: str,
    check_in: str,
    check_out: str,
    guests: int = 2,
    rooms: int = 1,
    hotel_name: str = ""
):
    """í˜¸í…” ê²€ìƒ‰ ë° ì˜ˆì•½ ë§í¬ë¥¼ ìƒì„±í•˜ëŠ” í†µí•© API"""
    try:
        hotel_service = HotelSearchService()
        
        # ì¸ê¸° í˜¸í…” ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤
        popular_hotels = hotel_service.get_popular_hotels(destination)
        
        # ê° í˜¸í…”ì— ì˜ˆì•½ ë§í¬ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤
        for hotel in popular_hotels:
            hotel["booking_links"] = hotel_service.create_booking_links(
                destination, check_in, check_out, guests, rooms, hotel["name"]
            )
        
        # ì¼ë°˜ì ì¸ ê²€ìƒ‰ ë§í¬ë„ ì œê³µí•©ë‹ˆë‹¤
        general_links = hotel_service.create_booking_links(
            destination, check_in, check_out, guests, rooms, hotel_name
        )
        
        return {
            "destination": destination,
            "check_in": check_in,
            "check_out": check_out,
            "guests": guests,
            "rooms": rooms,
            "popular_hotels": popular_hotels,
            "general_search_links": general_links
        }
    except Exception as e:
        logger.error(f"í˜¸í…” ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise HTTPException(status_code=500, detail=f"í˜¸í…” ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.get("/health")
async def health_check():
    """ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•˜ëŠ” API (í—¬ìŠ¤ ì²´í¬)"""
    return {"status": "healthy", "openai_key_set": bool(openai_api_key)}

# ========================================
# ëŒ€ì¤‘êµí†µ ì •ë³´ API ì—”ë“œí¬ì¸íŠ¸
# ========================================


# ========================================
# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
# ========================================
# ì´ íŒŒì¼ì„ ì§ì ‘ ì‹¤í–‰í•  ë•Œë§Œ ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤
if __name__ == "__main__":
    import uvicorn  # ASGI ì„œë²„ (FastAPIë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì„œë²„)
    
    print("=== ì„œë²„ ì‹œì‘ ===")
    uvicorn.run(app, host="0.0.0.0", port=8000)  # ëª¨ë“  IPì—ì„œ ì ‘ê·¼ ê°€ëŠ¥, 8000ë²ˆ í¬íŠ¸ ì‚¬ìš©


# ========================================
# ìœ„ì¹˜ í”¼ë“œë°± ìˆ˜ì§‘ API ì—”ë“œí¬ì¸íŠ¸
# ========================================

from pydantic import BaseModel

class LocationFeedback(BaseModel):
    location: str
    feedback_type: str  # 'not-exist', 'wrong-info', etc.
    destination: str

@app.post("/location-feedback")
async def collect_location_feedback(feedback: LocationFeedback):
    """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì¥ì†Œì— ëŒ€í•œ ì‚¬ìš©ì í”¼ë“œë°±ì„ ìˆ˜ì§‘í•˜ëŠ” API"""
    try:
        logger.warning(f"ì¥ì†Œ ì˜¤ë¥˜ ì‹ ê³ : {feedback.location} in {feedback.destination} - íƒ€ì…: {feedback.feedback_type}")
        
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ê±°ë‚˜ ê´€ë¦¬ìì—ê²Œ ì•Œë¦¼ì„ ë³´ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤
        # í˜„ì¬ëŠ” ë¡œê·¸ë¡œë§Œ ê¸°ë¡í•©ë‹ˆë‹¤
        
        return {"success": True, "message": "í”¼ë“œë°±ì´ ì ‘ìˆ˜ë˜ì—ˆìŠµë‹ˆë‹¤."}
    except Exception as e:
        logger.error(f"í”¼ë“œë°± ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
        return {"success": False, "message": "í”¼ë“œë°± ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}



# ========================================
# ì±„íŒ…ì„ í†µí•œ ì¼ì • ìˆ˜ì • API ì—”ë“œí¬ì¸íŠ¸
# ========================================

@app.post("/modify-trip-chat")
async def modify_trip_chat(request: ChatModifyRequest):
    """ì±„íŒ…ì„ í†µí•´ ì—¬í–‰ ì¼ì •ì„ ìˆ˜ì •í•˜ëŠ” API"""
    try:
        logger.info(f"ì±„íŒ… ìˆ˜ì • ìš”ì²­: {request.message}")
        logger.info(f"í˜„ì¬ ì—¬í–‰ì§€: {request.current_trip_plan.get('destination', 'N/A')}")
        
        # OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜ì • ìš”ì²­ ì²˜ë¦¬
        client = openai.OpenAI(api_key=openai_api_key)
        
        # í˜„ì¬ ì¼ì • ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        current_plan_str = json.dumps(request.current_trip_plan, ensure_ascii=False, indent=2)
        
        # GPTì—ê²Œ ìˆ˜ì • ìš”ì²­ì„ ì²˜ë¦¬í•˜ë„ë¡ í•˜ëŠ” í”„ë¡¬í”„íŠ¸
        modify_prompt = f"""
Here is the current travel plan:

{current_plan_str}

User's modification request: "{request.message}"

Please modify the travel plan according to the above request.

**ğŸš¨ IMPORTANT LIMITATIONS:**
- **Activity addition limit**: Maximum 5 activities per day. Cannot add to days that already have 5 activities.
- **Activity deletion limit**: Must maintain minimum 2 activities per day. Cannot delete from days that only have 2 activities.

**Modification methods by function:**

1. **Activity addition requests**:
   - "Add more to Day 1", "Add one more activity to Day 2" â†’ Add 1 new activity to that day
   - "Add something to Day X afternoon" â†’ Add activity to afternoon time slot
   - **Limit check**: Cannot add if that day already has 5 activities.
   - New activity should be real tourist spot in that area
   - Assign appropriate time that doesn't conflict with existing activities
   - Choose new place that doesn't duplicate existing activities

2. **Activity removal requests**:
   - "Remove XX from Day 1", "Remove massage from Day 2" â†’ Completely remove that activity
   - "Remove Day X afternoon schedule" â†’ Remove activity from that time slot
   - **Limit check**: Cannot delete if that day only has 2 activities left.
   - Adjust other activities' times naturally if gap becomes too large after removal

3. **Activity replacement requests**:
   - "Change XX in Day 1 to somewhere else" â†’ Replace that activity with different activity at same time
   - "Change massage in Day 2 to restaurant" â†’ Replace with requested type of activity
   - Keep time slot and duration, only change content

4. **Activity swap/move requests**:
   - "Swap XX in Day 2 with â–³â–³ in Day 3" â†’ Exchange positions of two activities
   - "Move XX from Day 1 to Day 2" â†’ Move activity to different day
   - **Limit check**: Cannot move if target day already has 5 activities.
   - Adjust time slots to match each day's existing pattern

5. **Activity content changes**:
   - "Make XX in Day X more fun" â†’ Change to different activity at same place
   - "Make Day 1 more active" â†’ Change entire day to more active content

**Required compliance:**
- All new/changed places must be real, specific tourist spot names in that area
- Choose places that don't duplicate existing activities
- Maintain natural time flow
- Keep basic info like destination, duration, total_cost, tips unchanged
- **Update travel tips too**: Make tips more specific and practical to match modified schedule
- Maintain accurate JSON format
- **When limits violated**: Return JSON response with message that request is impossible

**Response format**: Return pure JSON without code blocks.

**Example processing**:
- "Add more to Day 1" â†’ Add 1 new tourist spot activity to Day 1 (if less than 5)
- "Remove massage from Day 2" â†’ Remove massage-related activity from Day 2 (if 3 or more)
- "Change XX in Day 3 to restaurant" â†’ Replace that activity with local restaurant visit
- "Swap XX in Day 1 with â–³â–³ in Day 2" â†’ Exchange the days of two activities

**Response example when limits violated**:
```json
{{
    "success": false,
    "message": "Sorry, that day already has maximum 5 activities and cannot add more.",
    "current_activities": 5,
    "max_activities": 5
}}
```

or

```json
{{
    "success": false,
    "message": "Sorry, that day must maintain minimum 2 activities and cannot delete.",
    "current_activities": 2,
    "min_activities": 2
}}
```
"""

        try:
            completion = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì—¬í–‰ ê³„íš ìˆ˜ì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ê¸°ëŠ¥ë“¤ì„ ì •í™•íˆ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: 1) ì¼ì • ì¶”ê°€ ('ì¼ì • ëŠ˜ë ¤ì¤˜') 2) ì¼ì • ì œê±° ('â—‹â—‹ ë¹¼ì¤˜') 3) ì¼ì • êµì²´ ('â—‹â—‹ë¥¼ â–³â–³ë¡œ ë°”ê¿”ì¤˜') 4) ì¼ì • ì´ë™ ('Aì™€ B ë°”ê¿”ì¤˜') 5) í™œë™ ë³€ê²½ ('ë” ì¬ë¯¸ìˆê²Œ ë°”ê¿”ì¤˜'). ëª¨ë“  ìƒˆ ì¥ì†ŒëŠ” ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ê´€ê´‘ì§€ì—¬ì•¼ í•˜ë©°, ê¸°ì¡´ ì¥ì†Œì™€ ì¤‘ë³µë˜ë©´ ì•ˆ ë©ë‹ˆë‹¤. ì½”ë“œ ë¸”ë¡ì´ë‚˜ ì„¤ëª… ì—†ì´ ìˆœìˆ˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."},
                    {"role": "user", "content": modify_prompt}
                ],
                max_tokens=3000,
                temperature=0.7
            )
            
            response_content = completion.choices[0].message.content.strip()
            logger.info(f"OpenAI ì‘ë‹µ (ì²˜ìŒ 200ì): {response_content[:200]}...")
            
            # JSON íŒŒì‹± ì‹œë„ (ë” ê°•ë ¥í•œ ì •ë¦¬)
            try:
                # ë‹¤ì–‘í•œ í˜•íƒœì˜ ì½”ë“œ ë¸”ë¡ ì œê±°
                content = response_content.strip()
                
                # ```jsonì´ë‚˜ ``` ì½”ë“œ ë¸”ë¡ ì œê±°
                if content.startswith('```'):
                    lines = content.split('\n')
                    # ì²« ë²ˆì§¸ ```ê°€ ìˆëŠ” ì¤„ ì œê±°
                    if lines[0].strip() in ['```', '```json']:
                        lines = lines[1:]
                    # ë§ˆì§€ë§‰ ```ê°€ ìˆëŠ” ì¤„ ì œê±°
                    if lines and lines[-1].strip() == '```':
                        lines = lines[:-1]
                    content = '\n'.join(lines)
                
                # ì•ë’¤ ê³µë°±ê³¼ ê°œí–‰ ì œê±°
                content = content.strip()
                
                # ì¶”ê°€ ì •ë¦¬: ë§¨ ì•ë’¤ì— ìˆëŠ” ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
                if content.startswith('"') and content.endswith('"'):
                    content = content[1:-1]
                
                # ì²« ë²ˆì§¸ {ë¶€í„° ë§ˆì§€ë§‰ }ê¹Œì§€ë§Œ ì¶”ì¶œ
                start_idx = content.find('{')
                end_idx = content.rfind('}')
                if start_idx != -1 and end_idx != -1 and start_idx < end_idx:
                    content = content[start_idx:end_idx+1]
                
                logger.info(f"ì •ë¦¬ëœ JSON (ì²˜ìŒ 200ì): {content[:200]}...")
                
                # JSON íŒŒì‹±
                modified_plan = json.loads(content)
                
                return {
                    "success": True,
                    "modified_plan": modified_plan,
                    "message": "ì¼ì •ì´ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤."
                }
                
            except json.JSONDecodeError as e:
                logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                logger.error(f"ì›ë³¸ ì‘ë‹µ: {response_content}")
                logger.error(f"ì •ë¦¬ëœ ë‚´ìš©: {content}")
                
                # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ë” ìƒì„¸í•œ ì•ˆë‚´ ì œê³µ
                return {
                    "success": False,
                    "message": f"'{request.message}' ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ì— ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                    "suggestion": "ë‹¤ìŒê³¼ ê°™ì´ ë” êµ¬ì²´ì ìœ¼ë¡œ ìš”ì²­í•´ì£¼ì„¸ìš”: '3ì¼ì°¨ ë§ˆì‚¬ì§€ë¥¼ í•´ìš´ëŒ€í•´ìˆ˜ìš•ì¥ ì‚°ì±…ìœ¼ë¡œ ë°”ê¿”ì¤˜', '2ì¼ì°¨ ì˜¤í›„ ì¼ì •ì„ ë§›ì§‘ íˆ¬ì–´ë¡œ ë°”ê¿”ì¤˜'"
                }
                
        except Exception as openai_error:
            logger.error(f"OpenAI API ì˜¤ë¥˜: {openai_error}")
            return {
                "success": False,
                "message": "ì¼ì • ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            }
            
    except Exception as e:
        logger.error(f"ì±„íŒ… ìˆ˜ì • ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return {
            "success": False,
            "message": "ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        }